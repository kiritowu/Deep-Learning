{"cells":[{"cell_type":"markdown","metadata":{"id":"Shmu9wk3UVj8"},"source":["## Google Colab Setup\n","\n","Skip this section if running locally\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2893,"status":"ok","timestamp":1644138981367,"user":{"displayName":"Muhammad Faqih Akmal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQ0Gv9uTEIjqztfgFQ3ZRDb-p9ZzwH_0sqIhp02Q=s64","userId":"03909925437233836922"},"user_tz":-480},"id":"JtZza2AQUVkB","outputId":"c22658cf-0a73-4a3c-fde2-464c7905398f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Great-Lunar-Lander'...\n","remote: Enumerating objects: 425, done.\u001b[K\n","remote: Counting objects: 100% (425/425), done.\u001b[K\n","remote: Compressing objects: 100% (288/288), done.\u001b[K\n","remote: Total 425 (delta 239), reused 305 (delta 127), pack-reused 0\u001b[K\n","Receiving objects: 100% (425/425), 3.45 MiB | 5.95 MiB/s, done.\n","Resolving deltas: 100% (239/239), done.\n","/content/Great-Lunar-Lander\n"]}],"source":["!git clone https://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@github.com/kiritowu/Great-Lunar-Lander.git\n","%cd Great-Lunar-Lander"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":25017,"status":"ok","timestamp":1644139008606,"user":{"displayName":"Muhammad Faqih Akmal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQ0Gv9uTEIjqztfgFQ3ZRDb-p9ZzwH_0sqIhp02Q=s64","userId":"03909925437233836922"},"user_tz":-480},"id":"dQh6BogLUVkF"},"outputs":[],"source":["%%capture\n","!pip install Box2D\n","!pip install box2d\n","!pip install box2d-py\n","!pip install gym[all]\n","!pip install gym[Box_2D]\n","!pip install wandb     "]},{"cell_type":"markdown","metadata":{"id":"-6XdiSRIUVkH"},"source":["## Setup\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2749,"status":"ok","timestamp":1644139011347,"user":{"displayName":"Muhammad Faqih Akmal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQ0Gv9uTEIjqztfgFQ3ZRDb-p9ZzwH_0sqIhp02Q=s64","userId":"03909925437233836922"},"user_tz":-480},"id":"15cRmf9jUVkI"},"outputs":[],"source":["import gym\n","\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","\n","from utils import seed_everything, Experience, ReplayBuffer\n","from collections import deque\n","from model.sarsa import SARSA"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":12691,"status":"ok","timestamp":1644139024026,"user":{"displayName":"Muhammad Faqih Akmal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQ0Gv9uTEIjqztfgFQ3ZRDb-p9ZzwH_0sqIhp02Q=s64","userId":"03909925437233836922"},"user_tz":-480},"id":"_jyCqjMbUVkK","outputId":"62cf8e18-2ce8-4887-d35c-6668a5b9a395"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","\n","wandb.login()\n"]},{"cell_type":"markdown","metadata":{"id":"TFSi3BYlUVkN"},"source":["## Define Train Function\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1644139034574,"user":{"displayName":"Muhammad Faqih Akmal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQ0Gv9uTEIjqztfgFQ3ZRDb-p9ZzwH_0sqIhp02Q=s64","userId":"03909925437233836922"},"user_tz":-480},"id":"bbWNHSoXUVkP"},"outputs":[],"source":["def train(config=None):\n","    with wandb.init(config=config):\n","        config = wandb.config\n","        env = gym.make(\"LunarLander-v2\")\n","        model = SARSA(\n","            env=env,\n","            lr=config.lr,\n","            gamma=config.gamma,\n","            epsilon=config.epsilon,\n","            epsilon_decay=config.epsilon_decay,\n","            log_wandb=True,\n","            tuning_condition=True,\n","        )\n","        model.train(config.episodes, mean_stopping=False)\n"]},{"cell_type":"markdown","metadata":{"id":"FynTiXmwUVkR"},"source":["## Start the Run\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":566,"status":"ok","timestamp":1644139037819,"user":{"displayName":"Muhammad Faqih Akmal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQ0Gv9uTEIjqztfgFQ3ZRDb-p9ZzwH_0sqIhp02Q=s64","userId":"03909925437233836922"},"user_tz":-480},"id":"byf5siR7UVkT"},"outputs":[],"source":["sweep_id = \"f1zo1g3l\"\n","project_name = \"SARSA-Tuning\"\n","num_runs = 50\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"kL2ZlFMyUVkU","outputId":"7376a956-0f25-4f32-981f-b0f73c36b146"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9vvredwu with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepisodes: 500\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon_decay: 0.961077339888314\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007278170416668749\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","2022-02-10 08:45:54.735860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tiencheng/GitHub/Great-Lunar-Lander/env/lib/python3.9/site-packages/cv2/../../lib64:\n","2022-02-10 08:45:54.735888: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/onsen/SARSA-Tuning/runs/9vvredwu\" target=\"_blank\">splendid-sweep-3</a></strong> to <a href=\"https://wandb.ai/onsen/SARSA-Tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/onsen/SARSA-Tuning/sweeps/f1zo1g3l\" target=\"_blank\">https://wandb.ai/onsen/SARSA-Tuning/sweeps/f1zo1g3l</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gamma' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epsilon' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epsilon_decay' was locked by 'sweep' (ignored update).\n"]},{"name":"stdout","output_type":"stream","text":["[000] Reward: -240.924 | Avg Reward: -240.924 | e: 0.961 | Episode Length:   79\n","[001] Reward: -157.771 | Avg Reward: -199.348 | e: 0.924 | Episode Length:   93\n","[002] Reward: -267.913 | Avg Reward: -222.203 | e: 0.888 | Episode Length:   83\n","[003] Reward: -270.423 | Avg Reward: -234.258 | e: 0.853 | Episode Length:  102\n","[004] Reward: -411.768 | Avg Reward: -269.760 | e: 0.820 | Episode Length:   85\n","[005] Reward: -104.930 | Avg Reward: -242.288 | e: 0.788 | Episode Length:  112\n","[006] Reward: -346.202 | Avg Reward: -257.133 | e: 0.757 | Episode Length:  148\n","[007] Reward: -188.794 | Avg Reward: -248.591 | e: 0.728 | Episode Length:   60\n","[008] Reward: -109.301 | Avg Reward: -233.114 | e: 0.700 | Episode Length:  116\n","[009] Reward: -268.174 | Avg Reward: -236.620 | e: 0.672 | Episode Length:   95\n","[010] Reward: -278.871 | Avg Reward: -240.461 | e: 0.646 | Episode Length:   91\n","[011] Reward:    9.035 | Avg Reward: -219.670 | e: 0.621 | Episode Length:  124\n","[012] Reward:  -76.137 | Avg Reward: -208.629 | e: 0.597 | Episode Length:  108\n","[013] Reward: -467.263 | Avg Reward: -227.103 | e: 0.574 | Episode Length:   76\n","[014] Reward:   36.150 | Avg Reward: -209.552 | e: 0.551 | Episode Length:   67\n","[015] Reward: -283.146 | Avg Reward: -214.152 | e: 0.530 | Episode Length:   88\n","[016] Reward: -335.128 | Avg Reward: -221.268 | e: 0.509 | Episode Length:   78\n","[017] Reward: -484.120 | Avg Reward: -235.871 | e: 0.489 | Episode Length:  244\n","[018] Reward: -467.109 | Avg Reward: -248.042 | e: 0.470 | Episode Length:   92\n","[019] Reward: -419.716 | Avg Reward: -256.625 | e: 0.452 | Episode Length:   60\n","[020] Reward: -355.516 | Avg Reward: -261.334 | e: 0.434 | Episode Length:   69\n","[021] Reward: -460.740 | Avg Reward: -270.398 | e: 0.418 | Episode Length:   78\n","[022] Reward: -348.418 | Avg Reward: -273.790 | e: 0.401 | Episode Length:  101\n","[023] Reward: -310.670 | Avg Reward: -275.327 | e: 0.386 | Episode Length:   64\n","[024] Reward: -100.241 | Avg Reward: -268.324 | e: 0.371 | Episode Length:   93\n","[025] Reward: -343.589 | Avg Reward: -271.218 | e: 0.356 | Episode Length:   70\n","[026] Reward:  -25.124 | Avg Reward: -262.104 | e: 0.342 | Episode Length:   93\n","[027] Reward: -207.513 | Avg Reward: -260.154 | e: 0.329 | Episode Length:  149\n","[028] Reward:  -76.879 | Avg Reward: -253.834 | e: 0.316 | Episode Length:   71\n"]},{"name":"stderr","output_type":"stream","text":["2022-02-10 08:49:06.470047: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n","2022-02-10 08:49:06.481326: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"]},{"name":"stdout","output_type":"stream","text":["[029] Reward: -203.099 | Avg Reward: -252.143 | e: 0.304 | Episode Length:   54\n","[030] Reward:  -87.683 | Avg Reward: -246.838 | e: 0.292 | Episode Length:   99\n"]},{"name":"stderr","output_type":"stream","text":["2022-02-10 08:49:16.365476: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"]},{"name":"stdout","output_type":"stream","text":["[031] Reward:  -75.699 | Avg Reward: -241.490 | e: 0.281 | Episode Length:   77\n","[032] Reward: -109.918 | Avg Reward: -237.503 | e: 0.270 | Episode Length:  137\n","[033] Reward: -466.705 | Avg Reward: -244.244 | e: 0.259 | Episode Length:   68\n","[034] Reward: -138.387 | Avg Reward: -241.220 | e: 0.249 | Episode Length:   97\n","[035] Reward: -152.160 | Avg Reward: -238.746 | e: 0.239 | Episode Length:   97\n","[036] Reward: -124.059 | Avg Reward: -235.646 | e: 0.230 | Episode Length:   76\n","[037] Reward: -260.373 | Avg Reward: -236.297 | e: 0.221 | Episode Length:  144\n","[038] Reward: -133.134 | Avg Reward: -233.652 | e: 0.213 | Episode Length:   84\n","[039] Reward:  -84.874 | Avg Reward: -229.932 | e: 0.204 | Episode Length:   81\n","[040] Reward: -219.303 | Avg Reward: -229.673 | e: 0.196 | Episode Length:  106\n","[041] Reward: -427.936 | Avg Reward: -234.394 | e: 0.189 | Episode Length:  110\n","[042] Reward: -281.576 | Avg Reward: -235.491 | e: 0.181 | Episode Length:   91\n","[043] Reward: -139.638 | Avg Reward: -233.312 | e: 0.174 | Episode Length:  115\n","[044] Reward:  -74.936 | Avg Reward: -229.793 | e: 0.168 | Episode Length:   66\n","[045] Reward: -483.270 | Avg Reward: -235.303 | e: 0.161 | Episode Length:   90\n","[046] Reward: -250.334 | Avg Reward: -235.623 | e: 0.155 | Episode Length:   78\n","[047] Reward: -213.118 | Avg Reward: -235.154 | e: 0.149 | Episode Length:   60\n","[048] Reward: -766.160 | Avg Reward: -245.991 | e: 0.143 | Episode Length:  267\n","[049] Reward: -258.017 | Avg Reward: -246.232 | e: 0.137 | Episode Length:  208\n","[050] Reward: -518.763 | Avg Reward: -251.575 | e: 0.132 | Episode Length:   81\n","Training stopped early: Episode 51 with -254.236 mean reward\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 23512... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg-Reward-100e</td><td>▄█▆▅▄▃▃▅▄▆▇▇▇▆▅▃▂▁▁▂▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▄▃</td></tr><tr><td>Episode</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Episode Length</td><td>▂▂▂▃▃▄▁▃▂▃▃▁▂▂▇▁▁▂▁▂▂▂▂▁▂▄▁▂▂▄▂▂▃▂▃▁▂▁█▂</td></tr><tr><td>Epsilon</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Reward</td><td>▆▆▅▅▇▅▆▇▅█▇█▅▅▃▄▅▄▅▇▅▇▇▆▇▇▄▆▆▅▇▇▄▅▆▇▆▆▁▃</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg-Reward-100e</td><td>-251.57529</td></tr><tr><td>Episode</td><td>50</td></tr><tr><td>Episode Length</td><td>81</td></tr><tr><td>Epsilon</td><td>0.13203</td></tr><tr><td>Reward</td><td>-518.76291</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">splendid-sweep-3</strong>: <a href=\"https://wandb.ai/onsen/SARSA-Tuning/runs/9vvredwu\" target=\"_blank\">https://wandb.ai/onsen/SARSA-Tuning/runs/9vvredwu</a><br/>\n","Find logs at: <code>./wandb/run-20220210_084553-9vvredwu/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8tskbwty with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepisodes: 500\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon_decay: 0.9698069345435544\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tgamma: 0.99\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007451520044093457\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","2022-02-10 08:52:56.407781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tiencheng/GitHub/Great-Lunar-Lander/env/lib/python3.9/site-packages/cv2/../../lib64:\n","2022-02-10 08:52:56.407837: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/onsen/SARSA-Tuning/runs/8tskbwty\" target=\"_blank\">fancy-sweep-5</a></strong> to <a href=\"https://wandb.ai/onsen/SARSA-Tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/onsen/SARSA-Tuning/sweeps/f1zo1g3l\" target=\"_blank\">https://wandb.ai/onsen/SARSA-Tuning/sweeps/f1zo1g3l</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gamma' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epsilon' was locked by 'sweep' (ignored update).\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epsilon_decay' was locked by 'sweep' (ignored update).\n"]},{"name":"stdout","output_type":"stream","text":["[000] Reward: -175.017 | Avg Reward: -175.017 | e: 0.970 | Episode Length:   62\n","[001] Reward: -108.289 | Avg Reward: -141.653 | e: 0.941 | Episode Length:  106\n","[002] Reward: -100.604 | Avg Reward: -127.970 | e: 0.912 | Episode Length:   93\n","[003] Reward: -194.442 | Avg Reward: -144.588 | e: 0.885 | Episode Length:  100\n","[004] Reward: -157.087 | Avg Reward: -147.088 | e: 0.858 | Episode Length:   89\n","[005] Reward: -158.170 | Avg Reward: -148.935 | e: 0.832 | Episode Length:   73\n","[006] Reward: -222.048 | Avg Reward: -159.380 | e: 0.807 | Episode Length:  136\n","[007] Reward: -123.665 | Avg Reward: -154.915 | e: 0.782 | Episode Length:  168\n","[008] Reward: -114.320 | Avg Reward: -150.405 | e: 0.759 | Episode Length:  108\n","[009] Reward: -125.600 | Avg Reward: -147.924 | e: 0.736 | Episode Length:   90\n","[010] Reward: -106.576 | Avg Reward: -144.165 | e: 0.714 | Episode Length:  104\n","[011] Reward: -380.467 | Avg Reward: -163.857 | e: 0.692 | Episode Length:  126\n","[012] Reward:  -78.212 | Avg Reward: -157.269 | e: 0.671 | Episode Length:   99\n","[013] Reward: -130.504 | Avg Reward: -155.357 | e: 0.651 | Episode Length:  170\n","[014] Reward:  -91.957 | Avg Reward: -151.131 | e: 0.631 | Episode Length:   88\n","[015] Reward:  -89.899 | Avg Reward: -147.304 | e: 0.612 | Episode Length:   89\n","[016] Reward:  -69.987 | Avg Reward: -142.756 | e: 0.594 | Episode Length:  104\n","[017] Reward:  -41.431 | Avg Reward: -137.126 | e: 0.576 | Episode Length:  170\n","[018] Reward:  -76.156 | Avg Reward: -133.917 | e: 0.558 | Episode Length:  122\n","[019] Reward:  -64.628 | Avg Reward: -130.453 | e: 0.542 | Episode Length:  106\n","[020] Reward:  -10.497 | Avg Reward: -124.741 | e: 0.525 | Episode Length:  297\n","[021] Reward:  -30.640 | Avg Reward: -120.464 | e: 0.509 | Episode Length:  140\n","[022] Reward: -182.018 | Avg Reward: -123.140 | e: 0.494 | Episode Length:  118\n","[023] Reward: -113.336 | Avg Reward: -122.731 | e: 0.479 | Episode Length:  120\n","[024] Reward:  -51.275 | Avg Reward: -119.873 | e: 0.465 | Episode Length:  212\n","[025] Reward:  -13.953 | Avg Reward: -115.799 | e: 0.451 | Episode Length:  225\n","[026] Reward:    5.887 | Avg Reward: -111.292 | e: 0.437 | Episode Length:  416\n","[027] Reward:   78.614 | Avg Reward: -104.510 | e: 0.424 | Episode Length:  999\n","[028] Reward:  127.442 | Avg Reward:  -96.512 | e: 0.411 | Episode Length:  999\n","[029] Reward:  152.690 | Avg Reward:  -88.205 | e: 0.399 | Episode Length:  999\n","[030] Reward:  -47.127 | Avg Reward:  -86.880 | e: 0.387 | Episode Length:  411\n","[031] Reward: -331.224 | Avg Reward:  -94.516 | e: 0.375 | Episode Length:  368\n","[032] Reward:   85.933 | Avg Reward:  -89.047 | e: 0.364 | Episode Length:  999\n","[033] Reward:  -85.883 | Avg Reward:  -88.954 | e: 0.353 | Episode Length:  248\n","[034] Reward:  -64.269 | Avg Reward:  -88.249 | e: 0.342 | Episode Length:  318\n","[035] Reward:  -77.205 | Avg Reward:  -87.942 | e: 0.332 | Episode Length:  215\n","[036] Reward:   21.720 | Avg Reward:  -84.978 | e: 0.322 | Episode Length:  999\n","[037] Reward:  -35.301 | Avg Reward:  -83.671 | e: 0.312 | Episode Length:  178\n","[038] Reward:   17.524 | Avg Reward:  -81.076 | e: 0.303 | Episode Length:  188\n","[039] Reward: -110.195 | Avg Reward:  -81.804 | e: 0.293 | Episode Length:  340\n","[040] Reward:   13.372 | Avg Reward:  -79.483 | e: 0.285 | Episode Length:  312\n","[041] Reward:   33.562 | Avg Reward:  -76.791 | e: 0.276 | Episode Length:  209\n","[042] Reward:    4.420 | Avg Reward:  -74.903 | e: 0.268 | Episode Length:  251\n","[043] Reward:   -4.082 | Avg Reward:  -73.293 | e: 0.260 | Episode Length:  313\n","[044] Reward:   16.605 | Avg Reward:  -71.295 | e: 0.252 | Episode Length:  228\n","[045] Reward:  135.613 | Avg Reward:  -66.797 | e: 0.244 | Episode Length:  999\n","[046] Reward:  -25.150 | Avg Reward:  -65.911 | e: 0.237 | Episode Length:  280\n","[047] Reward:   93.209 | Avg Reward:  -62.596 | e: 0.230 | Episode Length:  928\n","[048] Reward:  203.023 | Avg Reward:  -57.176 | e: 0.223 | Episode Length:  529\n","[049] Reward:  -45.800 | Avg Reward:  -56.948 | e: 0.216 | Episode Length:  999\n","[050] Reward: -273.539 | Avg Reward:  -61.195 | e: 0.209 | Episode Length:  647\n","[051] Reward:  -19.228 | Avg Reward:  -60.388 | e: 0.203 | Episode Length:  254\n","[052] Reward:  129.046 | Avg Reward:  -56.814 | e: 0.197 | Episode Length:  999\n","[053] Reward:  197.678 | Avg Reward:  -52.101 | e: 0.191 | Episode Length:  593\n","[054] Reward: -344.195 | Avg Reward:  -57.412 | e: 0.185 | Episode Length:  102\n","[055] Reward:   58.021 | Avg Reward:  -55.350 | e: 0.180 | Episode Length:  204\n","[056] Reward:  250.878 | Avg Reward:  -49.978 | e: 0.174 | Episode Length:  665\n","[057] Reward:  -99.530 | Avg Reward:  -50.832 | e: 0.169 | Episode Length:  158\n","[058] Reward:  -62.992 | Avg Reward:  -51.038 | e: 0.164 | Episode Length:  330\n"]},{"name":"stderr","output_type":"stream","text":["2022-02-10 09:19:10.933616: W tensorflow/core/data/root_dataset.cc:163] Optimization loop failed: CANCELLED: Operation was cancelled\n"]},{"name":"stdout","output_type":"stream","text":["[059] Reward:   -7.370 | Avg Reward:  -50.311 | e: 0.159 | Episode Length:  226\n","[060] Reward:  224.971 | Avg Reward:  -45.798 | e: 0.154 | Episode Length:  642\n","[061] Reward:   22.579 | Avg Reward:  -44.695 | e: 0.149 | Episode Length:  198\n","[062] Reward:  -41.964 | Avg Reward:  -44.652 | e: 0.145 | Episode Length:  251\n","[063] Reward:  -25.686 | Avg Reward:  -44.355 | e: 0.141 | Episode Length:  108\n","[064] Reward:   25.181 | Avg Reward:  -43.285 | e: 0.136 | Episode Length:  311\n","[065] Reward:  206.230 | Avg Reward:  -39.505 | e: 0.132 | Episode Length:  671\n","[066] Reward:  224.859 | Avg Reward:  -35.559 | e: 0.128 | Episode Length:  364\n","[067] Reward: -167.733 | Avg Reward:  -37.503 | e: 0.124 | Episode Length:  837\n","[068] Reward:  164.462 | Avg Reward:  -34.576 | e: 0.121 | Episode Length:  469\n","[069] Reward:  -41.219 | Avg Reward:  -34.671 | e: 0.117 | Episode Length:  438\n","[070] Reward:  -38.918 | Avg Reward:  -34.731 | e: 0.113 | Episode Length:  212\n","[071] Reward:  101.304 | Avg Reward:  -32.841 | e: 0.110 | Episode Length:  999\n","[072] Reward:  275.283 | Avg Reward:  -28.620 | e: 0.107 | Episode Length:  777\n","[073] Reward:  -80.391 | Avg Reward:  -29.320 | e: 0.103 | Episode Length:  265\n","[074] Reward:  191.727 | Avg Reward:  -26.373 | e: 0.100 | Episode Length:  347\n","[075] Reward: -112.999 | Avg Reward:  -27.512 | e: 0.097 | Episode Length:  281\n","[076] Reward: -220.996 | Avg Reward:  -30.025 | e: 0.094 | Episode Length:  230\n","[077] Reward:  194.049 | Avg Reward:  -27.152 | e: 0.092 | Episode Length:  417\n","[078] Reward: -106.597 | Avg Reward:  -28.158 | e: 0.089 | Episode Length:  448\n","[079] Reward:  243.201 | Avg Reward:  -24.766 | e: 0.086 | Episode Length:  397\n","[080] Reward:  -63.592 | Avg Reward:  -25.245 | e: 0.083 | Episode Length:  572\n","[081] Reward:  232.338 | Avg Reward:  -22.104 | e: 0.081 | Episode Length:  451\n","[082] Reward:  -19.793 | Avg Reward:  -22.076 | e: 0.079 | Episode Length:  314\n","[083] Reward:  242.903 | Avg Reward:  -18.922 | e: 0.076 | Episode Length:  506\n","[084] Reward:  251.021 | Avg Reward:  -15.746 | e: 0.074 | Episode Length:  454\n","[085] Reward:  -75.256 | Avg Reward:  -16.438 | e: 0.072 | Episode Length:  246\n","[086] Reward:  -18.618 | Avg Reward:  -16.463 | e: 0.069 | Episode Length:  331\n","[087] Reward:  268.456 | Avg Reward:  -13.225 | e: 0.067 | Episode Length:  327\n"]}],"source":["wandb.agent(sweep_id, train, count=num_runs, entity=\"onsen\", project=project_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2DwuCTBUVkV"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"sweep_ddqn.ipynb","provenance":[]},"interpreter":{"hash":"281a0cf60699b28b581439b2552e60084f305e3074a42d9e1cf07374cc8c9220"},"kernelspec":{"display_name":"Python 3.9.7 64-bit ('env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
