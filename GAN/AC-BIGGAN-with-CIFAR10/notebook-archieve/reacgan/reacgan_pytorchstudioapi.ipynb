{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reacgan-pytorchstudioapi.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRNzWYwJdcnzZo/AtzejYl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiritowu/GAN/blob/main/reacgan_pytorchstudioapi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU8kZeSrvL3n",
        "outputId": "2ec85dfa-9c35-4ac1-b55d-af72d7228c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
            "Requirement already satisfied: torch==1.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.11.1+cu111 in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torchaudio==0.10.0+cu111 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.1+cu111) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==1.10.0+cu111 torchvision==0.11.1+cu111 torchaudio==0.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U pyyaml tqdm ninja h5py kornia matplotlib pandas sklearn scipy seaborn wandb PyYaml click requests pyspng imageio-ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL_t8EtIvTLz",
        "outputId": "d515f2d8-839c-41b1-edc6-d92d3f9e020a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.2.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.7.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (8.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.27.1)\n",
            "Requirement already satisfied: pyspng in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.7/dist-packages (0.4.5)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (4.28.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.26)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests) (2.0.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click) (3.7.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/POSTECH-CVLab/PyTorch-StudioGAN\n",
        "%cd PyTorch-StudioGAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fem8BxNrvUCf",
        "outputId": "3820254a-ccc2-40d2-b945-24820c930454"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch-StudioGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 src/main.py -t -metrics is fid -cfg src/configs/CIFAR10/ReACGAN.yaml -data data -save model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv-CWIKvvT54",
        "outputId": "c0c3d983-0f2f-4dd9-f9d7-47f27cd0fd86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n",
            "170499072it [00:03, 49045477.01it/s]                   \n",
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "You have chosen a specific GPU. This will completely disable data parallelism.\n",
            "[INFO] 2022-01-15 17:21:05 > Run name : CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.DATA =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"name\": \"CIFAR10\",\n",
            "  \"img_size\": 32,\n",
            "  \"num_classes\": 10,\n",
            "  \"img_channels\": 3\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.MODEL =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"backbone\": \"big_resnet\",\n",
            "  \"g_cond_mtd\": \"cBN\",\n",
            "  \"d_cond_mtd\": \"D2DCE\",\n",
            "  \"aux_cls_type\": \"W/O\",\n",
            "  \"normalize_d_embed\": true,\n",
            "  \"d_embed_dim\": 512,\n",
            "  \"apply_g_sn\": true,\n",
            "  \"apply_d_sn\": true,\n",
            "  \"g_act_fn\": \"ReLU\",\n",
            "  \"d_act_fn\": \"ReLU\",\n",
            "  \"apply_attn\": true,\n",
            "  \"attn_g_loc\": [\n",
            "    2\n",
            "  ],\n",
            "  \"attn_d_loc\": [\n",
            "    1\n",
            "  ],\n",
            "  \"z_prior\": \"gaussian\",\n",
            "  \"z_dim\": 80,\n",
            "  \"w_dim\": \"N/A\",\n",
            "  \"g_shared_dim\": 128,\n",
            "  \"g_conv_dim\": 96,\n",
            "  \"d_conv_dim\": 96,\n",
            "  \"g_depth\": \"N/A\",\n",
            "  \"d_depth\": \"N/A\",\n",
            "  \"apply_g_ema\": true,\n",
            "  \"g_ema_decay\": 0.9999,\n",
            "  \"g_ema_start\": 1000,\n",
            "  \"g_init\": \"ortho\",\n",
            "  \"d_init\": \"ortho\"\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.LOSS =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"adv_loss\": \"hinge\",\n",
            "  \"cond_lambda\": 0.5,\n",
            "  \"tac_gen_lambda\": \"N/A\",\n",
            "  \"tac_dis_lambda\": \"N/A\",\n",
            "  \"mh_lambda\": \"N/A\",\n",
            "  \"apply_fm\": false,\n",
            "  \"fm_lambda\": \"N/A\",\n",
            "  \"apply_r1_reg\": false,\n",
            "  \"r1_lambda\": \"N/A\",\n",
            "  \"m_p\": 0.98,\n",
            "  \"temperature\": 0.5,\n",
            "  \"apply_wc\": false,\n",
            "  \"wc_bound\": \"N/A\",\n",
            "  \"apply_gp\": false,\n",
            "  \"gp_lambda\": \"N/A\",\n",
            "  \"apply_dra\": false,\n",
            "  \"dra_lambda\": \"N/A\",\n",
            "  \"apply_maxgp\": false,\n",
            "  \"maxgp_lambda\": \"N/A\",\n",
            "  \"apply_cr\": false,\n",
            "  \"cr_lambda\": \"N/A\",\n",
            "  \"apply_bcr\": false,\n",
            "  \"real_lambda\": \"N/A\",\n",
            "  \"fake_lambda\": \"N/A\",\n",
            "  \"apply_zcr\": false,\n",
            "  \"radius\": \"N/A\",\n",
            "  \"g_lambda\": \"N/A\",\n",
            "  \"d_lambda\": \"N/A\",\n",
            "  \"apply_lo\": false,\n",
            "  \"lo_alpha\": \"N/A\",\n",
            "  \"lo_beta\": \"N/A\",\n",
            "  \"lo_rate\": \"N/A\",\n",
            "  \"lo_lambda\": \"N/A\",\n",
            "  \"lo_steps4train\": \"N/A\",\n",
            "  \"lo_steps4eval\": \"N/A\",\n",
            "  \"apply_topk\": false,\n",
            "  \"topk_gamma\": \"N/A\",\n",
            "  \"topk_nu\": \"N/A\"\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.OPTIMIZATION =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"type_\": \"Adam\",\n",
            "  \"batch_size\": 128,\n",
            "  \"acml_steps\": 1,\n",
            "  \"g_lr\": 0.00028284271,\n",
            "  \"d_lr\": 0.00028284271,\n",
            "  \"g_weight_decay\": 0.0,\n",
            "  \"d_weight_decay\": 0.0,\n",
            "  \"momentum\": \"N/A\",\n",
            "  \"nesterov\": \"N/A\",\n",
            "  \"alpha\": \"N/A\",\n",
            "  \"beta1\": 0.5,\n",
            "  \"beta2\": 0.999,\n",
            "  \"d_first\": true,\n",
            "  \"g_updates_per_step\": 1,\n",
            "  \"d_updates_per_step\": 5,\n",
            "  \"total_steps\": 100000,\n",
            "  \"world_size\": 1\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.PRE =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"apply_rflip\": true,\n",
            "  \"crop_long_edge\": false,\n",
            "  \"resize_size\": null\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.AUG =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"apply_diffaug\": false,\n",
            "  \"apply_ada\": false,\n",
            "  \"cr_aug_type\": \"W/O\",\n",
            "  \"bcr_aug_type\": \"W/O\",\n",
            "  \"diffaug_type\": \"W/O\",\n",
            "  \"ada_aug_type\": \"W/O\",\n",
            "  \"ada_initial_augment_p\": \"N/A\",\n",
            "  \"ada_target\": \"N/A\",\n",
            "  \"ada_kimg\": \"N/A\",\n",
            "  \"ada_interval\": \"N/A\"\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.RUN =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"entity\": null,\n",
            "  \"project\": null,\n",
            "  \"cfg_file\": \"src/configs/CIFAR10/ReACGAN.yaml\",\n",
            "  \"data_dir\": \"data\",\n",
            "  \"save_dir\": \"model\",\n",
            "  \"ckpt_dir\": null,\n",
            "  \"load_best\": false,\n",
            "  \"seed\": 593,\n",
            "  \"distributed_data_parallel\": false,\n",
            "  \"backend\": \"nccl\",\n",
            "  \"total_nodes\": 1,\n",
            "  \"current_node\": 0,\n",
            "  \"num_workers\": 8,\n",
            "  \"synchronized_bn\": false,\n",
            "  \"mixed_precision\": false,\n",
            "  \"truncation_factor\": -1.0,\n",
            "  \"truncation_cutoff\": null,\n",
            "  \"batch_statistics\": false,\n",
            "  \"standing_statistics\": false,\n",
            "  \"standing_max_batch\": -1,\n",
            "  \"standing_step\": -1,\n",
            "  \"freezeD\": -1,\n",
            "  \"langevin_sampling\": false,\n",
            "  \"langevin_rate\": -1,\n",
            "  \"langevin_noise_std\": -1,\n",
            "  \"langevin_decay\": -1,\n",
            "  \"langevin_decay_steps\": -1,\n",
            "  \"langevin_steps\": -1,\n",
            "  \"train\": true,\n",
            "  \"load_train_hdf5\": false,\n",
            "  \"load_data_in_memory\": false,\n",
            "  \"eval_metrics\": [\n",
            "    \"is\",\n",
            "    \"fid\"\n",
            "  ],\n",
            "  \"num_eval\": 1,\n",
            "  \"resize_fn\": \"legacy\",\n",
            "  \"save_real_images\": false,\n",
            "  \"save_fake_images\": false,\n",
            "  \"vis_fake_images\": false,\n",
            "  \"k_nearest_neighbor\": false,\n",
            "  \"interpolation\": false,\n",
            "  \"frequency_analysis\": false,\n",
            "  \"tsne_analysis\": false,\n",
            "  \"intra_class_fid\": false,\n",
            "  \"GAN_train\": false,\n",
            "  \"GAN_test\": false,\n",
            "  \"resume_classifier_train\": false,\n",
            "  \"semantic_factorization\": false,\n",
            "  \"num_semantic_axis\": -1,\n",
            "  \"maximum_variations\": -1,\n",
            "  \"print_every\": 100,\n",
            "  \"save_every\": 2000,\n",
            "  \"eval_backbone\": \"Inception_V3\",\n",
            "  \"ref_dataset\": \"train\",\n",
            "  \"is_ref_dataset\": false,\n",
            "  \"fix_seed\": false\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > cfgs.STYLEGAN2 =\n",
            "[INFO] 2022-01-15 17:21:05 > {\n",
            "  \"cond_type\": [\n",
            "    \"PD\",\n",
            "    \"SPD\",\n",
            "    \"2C\",\n",
            "    \"D2DCE\"\n",
            "  ],\n",
            "  \"g_reg_interval\": \"N/A\",\n",
            "  \"d_reg_interval\": \"N/A\",\n",
            "  \"mapping_network\": \"N/A\",\n",
            "  \"style_mixing_p\": \"N/A\",\n",
            "  \"g_ema_kimg\": \"N/A\",\n",
            "  \"g_ema_rampup\": \"N/A\",\n",
            "  \"apply_pl_reg\": false,\n",
            "  \"pl_weight\": \"N/A\",\n",
            "  \"d_architecture\": \"N/A\",\n",
            "  \"d_epilogue_mbstd_group_size\": \"N/A\"\n",
            "}\n",
            "[INFO] 2022-01-15 17:21:05 > Load CIFAR10 train dataset.\n",
            "Files already downloaded and verified\n",
            "[INFO] 2022-01-15 17:21:06 > Train dataset size: 50000\n",
            "[INFO] 2022-01-15 17:21:06 > Load CIFAR10 train dataset.\n",
            "Files already downloaded and verified\n",
            "[INFO] 2022-01-15 17:21:07 > Eval dataset size: 50000\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[INFO] 2022-01-15 17:21:07 > Build a Generative Adversarial Network.\n",
            "[INFO] 2022-01-15 17:21:07 > Modules are located on './src/models.big_resnet'.\n",
            "[INFO] 2022-01-15 17:21:16 > Prepare exponential moving average generator with decay rate of 0.9999.\n",
            "Initialize the copied generator's parameters to be source parameters.\n",
            "[INFO] 2022-01-15 17:21:16 > Number of parameters: 9416196\n",
            "[INFO] 2022-01-15 17:21:16 > Generator(\n",
            "  (linear0): Linear(in_features=20, out_features=6144, bias=True)\n",
            "  (shared): Embedding(10, 128)\n",
            "  (blocks): ModuleList(\n",
            "    (0): ModuleList(\n",
            "      (0): GenBlock(\n",
            "        (bn1): BigGANConditionalBatchNorm2d(\n",
            "          (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (gain): Linear(in_features=148, out_features=384, bias=False)\n",
            "          (bias): Linear(in_features=148, out_features=384, bias=False)\n",
            "        )\n",
            "        (bn2): BigGANConditionalBatchNorm2d(\n",
            "          (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (gain): Linear(in_features=148, out_features=384, bias=False)\n",
            "          (bias): Linear(in_features=148, out_features=384, bias=False)\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): ModuleList(\n",
            "      (0): GenBlock(\n",
            "        (bn1): BigGANConditionalBatchNorm2d(\n",
            "          (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (gain): Linear(in_features=148, out_features=384, bias=False)\n",
            "          (bias): Linear(in_features=148, out_features=384, bias=False)\n",
            "        )\n",
            "        (bn2): BigGANConditionalBatchNorm2d(\n",
            "          (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (gain): Linear(in_features=148, out_features=384, bias=False)\n",
            "          (bias): Linear(in_features=148, out_features=384, bias=False)\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (2): ModuleList(\n",
            "      (0): SelfAttention(\n",
            "        (conv1x1_theta): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv1x1_phi): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv1x1_g): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv1x1_attn): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "    )\n",
            "    (3): ModuleList(\n",
            "      (0): GenBlock(\n",
            "        (bn1): BigGANConditionalBatchNorm2d(\n",
            "          (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (gain): Linear(in_features=148, out_features=384, bias=False)\n",
            "          (bias): Linear(in_features=148, out_features=384, bias=False)\n",
            "        )\n",
            "        (bn2): BigGANConditionalBatchNorm2d(\n",
            "          (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "          (gain): Linear(in_features=148, out_features=384, bias=False)\n",
            "          (bias): Linear(in_features=148, out_features=384, bias=False)\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bn4): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (activation): ReLU(inplace=True)\n",
            "  (conv2d5): Conv2d(384, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (tanh): Tanh()\n",
            ")\n",
            "[INFO] 2022-01-15 17:21:16 > Number of parameters: 2517186\n",
            "[INFO] 2022-01-15 17:21:16 > Discriminator(\n",
            "  (blocks): ModuleList(\n",
            "    (0): ModuleList(\n",
            "      (0): DiscOptBlock(\n",
            "        (conv2d0): Conv2d(3, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv2d1): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "    (1): ModuleList(\n",
            "      (0): SelfAttention(\n",
            "        (conv1x1_theta): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv1x1_phi): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv1x1_g): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv1x1_attn): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "    )\n",
            "    (2): ModuleList(\n",
            "      (0): DiscBlock(\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (conv2d0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "    (3): ModuleList(\n",
            "      (0): DiscBlock(\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "    (4): ModuleList(\n",
            "      (0): DiscBlock(\n",
            "        (activation): ReLU(inplace=True)\n",
            "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (activation): ReLU(inplace=True)\n",
            "  (linear1): Linear(in_features=192, out_features=1, bias=True)\n",
            "  (linear2): Linear(in_features=192, out_features=512, bias=True)\n",
            "  (embedding): Embedding(10, 512)\n",
            ")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:83: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:03<00:00, 31.5MB/s]\n",
            "[INFO] 2022-01-15 17:21:21 > Calculate moments of train dataset using Inception_V3 model.\n",
            "100% 391/391 [02:34<00:00,  2.53it/s]\n",
            "[INFO] 2022-01-15 17:24:04 > Save calculated means and covariances to disk.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCIFAR10-ReACGAN-train-2022_01_15_17_20_59\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kiritowu/PyTorch-StudioGAN-src\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/kiritowu/PyTorch-StudioGAN-src/runs/2dzu2120\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in model/wandb/run-20220115_172526-2dzu2120\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "[INFO] 2022-01-15 17:25:30 > Start training!\n",
            "[INFO] 2022-01-15 17:27:20 > Step:    100 Progress: 0.1% Elapsed: 0:01:50 Gen_loss: 4.578 Dis_loss: 2.718 Cls_loss: 4.423 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:29:07 > Step:    200 Progress: 0.2% Elapsed: 0:03:37 Gen_loss: 3.572 Dis_loss: 3.825 Cls_loss: 4.29 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:30:54 > Step:    300 Progress: 0.3% Elapsed: 0:05:24 Gen_loss: 4.034 Dis_loss: 3.143 Cls_loss: 4.207 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:32:42 > Step:    400 Progress: 0.4% Elapsed: 0:07:11 Gen_loss: 1.941 Dis_loss: 3.207 Cls_loss: 4.267 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:34:28 > Step:    500 Progress: 0.5% Elapsed: 0:08:58 Gen_loss: 3.781 Dis_loss: 3.087 Cls_loss: 4.171 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:36:15 > Step:    600 Progress: 0.6% Elapsed: 0:10:44 Gen_loss: 2.075 Dis_loss: 3.043 Cls_loss: 4.142 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:38:01 > Step:    700 Progress: 0.7% Elapsed: 0:12:31 Gen_loss: 3.789 Dis_loss: 3.352 Cls_loss: 4.029 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:39:49 > Step:    800 Progress: 0.8% Elapsed: 0:14:18 Gen_loss: 2.237 Dis_loss: 2.765 Cls_loss: 3.969 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:41:35 > Step:    900 Progress: 0.9% Elapsed: 0:16:05 Gen_loss: 3.591 Dis_loss: 2.621 Cls_loss: 3.951 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:43:22 > Step:   1000 Progress: 1.0% Elapsed: 0:17:51 Gen_loss: 1.654 Dis_loss: 2.667 Cls_loss: 3.925 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:45:09 > Step:   1100 Progress: 1.1% Elapsed: 0:19:39 Gen_loss: 4.063 Dis_loss: 2.718 Cls_loss: 3.767 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:46:56 > Step:   1200 Progress: 1.2% Elapsed: 0:21:25 Gen_loss: 3.049 Dis_loss: 2.858 Cls_loss: 3.833 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:48:42 > Step:   1300 Progress: 1.3% Elapsed: 0:23:12 Gen_loss: 3.193 Dis_loss: 2.73 Cls_loss: 3.793 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:50:29 > Step:   1400 Progress: 1.4% Elapsed: 0:24:58 Gen_loss: 2.553 Dis_loss: 2.789 Cls_loss: 3.834 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:52:16 > Step:   1500 Progress: 1.5% Elapsed: 0:26:46 Gen_loss: 2.848 Dis_loss: 2.645 Cls_loss: 3.783 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:54:02 > Step:   1600 Progress: 1.6% Elapsed: 0:28:32 Gen_loss: 2.739 Dis_loss: 2.69 Cls_loss: 3.743 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:55:49 > Step:   1700 Progress: 1.7% Elapsed: 0:30:19 Gen_loss: 2.807 Dis_loss: 2.586 Cls_loss: 3.656 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:57:36 > Step:   1800 Progress: 1.8% Elapsed: 0:32:06 Gen_loss: 4.031 Dis_loss: 2.774 Cls_loss: 3.603 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 17:59:23 > Step:   1900 Progress: 1.9% Elapsed: 0:33:52 Gen_loss: 3.04 Dis_loss: 2.901 Cls_loss: 3.701 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:01:09 > Step:   2000 Progress: 2.0% Elapsed: 0:35:39 Gen_loss: 1.858 Dis_loss: 2.647 Cls_loss: 3.547 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:01:09 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 18:01:09 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_2000.png\n",
            "[INFO] 2022-01-15 18:01:09 > Start Evaluation (2000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 18:01:09 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:15<00:00,  1.53it/s]\n",
            "[INFO] 2022-01-15 18:05:25 > Inception score (Step: 2000, 50000 generated images): 7.096081256866455\n",
            "[INFO] 2022-01-15 18:05:40 > FID score (Step: 2000, Using train moments): 32.33326892493346\n",
            "[INFO] 2022-01-15 18:05:40 > Best FID score (Step: 2000, Using train moments): 32.33326892493346\n",
            "[INFO] 2022-01-15 18:05:41 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 18:07:27 > Step:   2100 Progress: 2.1% Elapsed: 0:41:57 Gen_loss: 2.456 Dis_loss: 2.528 Cls_loss: 3.626 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:09:15 > Step:   2200 Progress: 2.2% Elapsed: 0:43:45 Gen_loss: 2.905 Dis_loss: 2.521 Cls_loss: 3.556 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:11:02 > Step:   2300 Progress: 2.3% Elapsed: 0:45:31 Gen_loss: 3.619 Dis_loss: 2.979 Cls_loss: 3.6 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:12:48 > Step:   2400 Progress: 2.4% Elapsed: 0:47:18 Gen_loss: 3.052 Dis_loss: 2.355 Cls_loss: 3.455 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:14:35 > Step:   2500 Progress: 2.5% Elapsed: 0:49:05 Gen_loss: 3.281 Dis_loss: 2.426 Cls_loss: 3.614 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:16:22 > Step:   2600 Progress: 2.6% Elapsed: 0:50:52 Gen_loss: 2.911 Dis_loss: 2.45 Cls_loss: 3.443 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:18:08 > Step:   2700 Progress: 2.7% Elapsed: 0:52:38 Gen_loss: 2.331 Dis_loss: 2.443 Cls_loss: 3.563 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:19:55 > Step:   2800 Progress: 2.8% Elapsed: 0:54:25 Gen_loss: 1.976 Dis_loss: 2.487 Cls_loss: 3.412 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:21:42 > Step:   2900 Progress: 2.9% Elapsed: 0:56:12 Gen_loss: 2.336 Dis_loss: 2.409 Cls_loss: 3.3 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:23:29 > Step:   3000 Progress: 3.0% Elapsed: 0:57:59 Gen_loss: 2.857 Dis_loss: 2.596 Cls_loss: 3.486 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:25:15 > Step:   3100 Progress: 3.1% Elapsed: 0:59:45 Gen_loss: 3.315 Dis_loss: 2.495 Cls_loss: 3.283 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:27:03 > Step:   3200 Progress: 3.2% Elapsed: 1:01:33 Gen_loss: 3.388 Dis_loss: 2.558 Cls_loss: 3.341 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:28:49 > Step:   3300 Progress: 3.3% Elapsed: 1:03:19 Gen_loss: 2.976 Dis_loss: 2.287 Cls_loss: 3.191 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:30:36 > Step:   3400 Progress: 3.4% Elapsed: 1:05:06 Gen_loss: 2.563 Dis_loss: 2.45 Cls_loss: 3.34 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:32:22 > Step:   3500 Progress: 3.5% Elapsed: 1:06:52 Gen_loss: 2.663 Dis_loss: 2.579 Cls_loss: 3.344 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:34:10 > Step:   3600 Progress: 3.6% Elapsed: 1:08:40 Gen_loss: 3.306 Dis_loss: 2.5 Cls_loss: 3.292 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:35:56 > Step:   3700 Progress: 3.7% Elapsed: 1:10:26 Gen_loss: 2.156 Dis_loss: 2.66 Cls_loss: 3.344 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:37:43 > Step:   3800 Progress: 3.8% Elapsed: 1:12:13 Gen_loss: 3.413 Dis_loss: 2.515 Cls_loss: 3.308 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:39:29 > Step:   3900 Progress: 3.9% Elapsed: 1:13:59 Gen_loss: 2.823 Dis_loss: 2.478 Cls_loss: 3.398 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:41:17 > Step:   4000 Progress: 4.0% Elapsed: 1:15:47 Gen_loss: 2.661 Dis_loss: 2.393 Cls_loss: 3.277 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:41:17 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 18:41:17 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_4000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 18:41:17 > Start Evaluation (4000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 18:41:17 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:14<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 18:45:32 > Inception score (Step: 4000, 50000 generated images): 7.687808036804199\n",
            "[INFO] 2022-01-15 18:45:45 > FID score (Step: 4000, Using train moments): 28.494961568868064\n",
            "[INFO] 2022-01-15 18:45:45 > Best FID score (Step: 4000, Using train moments): 28.494961568868064\n",
            "[INFO] 2022-01-15 18:45:46 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 18:47:33 > Step:   4100 Progress: 4.1% Elapsed: 1:22:03 Gen_loss: 2.608 Dis_loss: 2.503 Cls_loss: 3.266 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:49:19 > Step:   4200 Progress: 4.2% Elapsed: 1:23:49 Gen_loss: 2.721 Dis_loss: 2.437 Cls_loss: 3.364 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:51:07 > Step:   4300 Progress: 4.3% Elapsed: 1:25:37 Gen_loss: 3.035 Dis_loss: 2.288 Cls_loss: 3.189 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:52:54 > Step:   4400 Progress: 4.4% Elapsed: 1:27:23 Gen_loss: 2.833 Dis_loss: 2.29 Cls_loss: 3.281 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:54:40 > Step:   4500 Progress: 4.5% Elapsed: 1:29:10 Gen_loss: 3.054 Dis_loss: 2.611 Cls_loss: 3.323 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:56:26 > Step:   4600 Progress: 4.6% Elapsed: 1:30:56 Gen_loss: 2.228 Dis_loss: 2.403 Cls_loss: 3.224 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 18:58:14 > Step:   4700 Progress: 4.7% Elapsed: 1:32:44 Gen_loss: 2.346 Dis_loss: 2.301 Cls_loss: 3.217 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:00:01 > Step:   4800 Progress: 4.8% Elapsed: 1:34:30 Gen_loss: 2.64 Dis_loss: 2.368 Cls_loss: 3.153 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:01:47 > Step:   4900 Progress: 4.9% Elapsed: 1:36:17 Gen_loss: 2.147 Dis_loss: 2.353 Cls_loss: 3.255 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:03:35 > Step:   5000 Progress: 5.0% Elapsed: 1:38:05 Gen_loss: 2.682 Dis_loss: 2.614 Cls_loss: 3.331 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:05:21 > Step:   5100 Progress: 5.1% Elapsed: 1:39:51 Gen_loss: 2.963 Dis_loss: 2.222 Cls_loss: 3.048 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:07:08 > Step:   5200 Progress: 5.2% Elapsed: 1:41:37 Gen_loss: 3.343 Dis_loss: 2.488 Cls_loss: 3.162 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:08:54 > Step:   5300 Progress: 5.3% Elapsed: 1:43:24 Gen_loss: 1.985 Dis_loss: 2.713 Cls_loss: 3.23 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:10:42 > Step:   5400 Progress: 5.4% Elapsed: 1:45:12 Gen_loss: 2.802 Dis_loss: 2.329 Cls_loss: 3.09 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:12:28 > Step:   5500 Progress: 5.5% Elapsed: 1:46:58 Gen_loss: 2.206 Dis_loss: 2.413 Cls_loss: 3.23 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:14:15 > Step:   5600 Progress: 5.6% Elapsed: 1:48:45 Gen_loss: 2.404 Dis_loss: 2.222 Cls_loss: 3.123 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:16:02 > Step:   5700 Progress: 5.7% Elapsed: 1:50:32 Gen_loss: 3.138 Dis_loss: 2.171 Cls_loss: 3.138 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:17:49 > Step:   5800 Progress: 5.8% Elapsed: 1:52:19 Gen_loss: 2.361 Dis_loss: 2.297 Cls_loss: 3.133 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:19:35 > Step:   5900 Progress: 5.9% Elapsed: 1:54:05 Gen_loss: 1.91 Dis_loss: 2.589 Cls_loss: 3.212 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:21:21 > Step:   6000 Progress: 6.0% Elapsed: 1:55:51 Gen_loss: 2.187 Dis_loss: 2.302 Cls_loss: 3.1 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:21:21 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 19:21:22 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_6000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 19:21:22 > Start Evaluation (6000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 19:21:22 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:14<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 19:25:36 > Inception score (Step: 6000, 50000 generated images): 7.912732124328613\n",
            "[INFO] 2022-01-15 19:25:50 > FID score (Step: 6000, Using train moments): 29.86997574106738\n",
            "[INFO] 2022-01-15 19:25:50 > Best FID score (Step: 4000, Using train moments): 28.494961568868064\n",
            "[INFO] 2022-01-15 19:25:51 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 19:27:38 > Step:   6100 Progress: 6.1% Elapsed: 2:02:08 Gen_loss: 2.341 Dis_loss: 2.243 Cls_loss: 2.999 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:29:24 > Step:   6200 Progress: 6.2% Elapsed: 2:03:54 Gen_loss: 3.011 Dis_loss: 2.409 Cls_loss: 3.167 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:31:11 > Step:   6300 Progress: 6.3% Elapsed: 2:05:41 Gen_loss: 3.191 Dis_loss: 2.333 Cls_loss: 3.139 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:32:58 > Step:   6400 Progress: 6.4% Elapsed: 2:07:28 Gen_loss: 2.122 Dis_loss: 2.355 Cls_loss: 3.061 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:34:45 > Step:   6500 Progress: 6.5% Elapsed: 2:09:15 Gen_loss: 2.378 Dis_loss: 2.486 Cls_loss: 3.214 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:36:31 > Step:   6600 Progress: 6.6% Elapsed: 2:11:01 Gen_loss: 2.775 Dis_loss: 2.476 Cls_loss: 3.216 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:38:18 > Step:   6700 Progress: 6.7% Elapsed: 2:12:48 Gen_loss: 3.151 Dis_loss: 2.406 Cls_loss: 3.167 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:40:05 > Step:   6800 Progress: 6.8% Elapsed: 2:14:35 Gen_loss: 2.804 Dis_loss: 2.163 Cls_loss: 3.023 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:41:52 > Step:   6900 Progress: 6.9% Elapsed: 2:16:22 Gen_loss: 3.362 Dis_loss: 2.347 Cls_loss: 3.185 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:43:38 > Step:   7000 Progress: 7.0% Elapsed: 2:18:08 Gen_loss: 3.199 Dis_loss: 2.428 Cls_loss: 3.148 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:45:26 > Step:   7100 Progress: 7.1% Elapsed: 2:19:56 Gen_loss: 2.808 Dis_loss: 2.153 Cls_loss: 3.053 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:47:12 > Step:   7200 Progress: 7.2% Elapsed: 2:21:42 Gen_loss: 2.951 Dis_loss: 2.105 Cls_loss: 3.074 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:48:59 > Step:   7300 Progress: 7.3% Elapsed: 2:23:29 Gen_loss: 2.4 Dis_loss: 2.336 Cls_loss: 3.098 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:50:45 > Step:   7400 Progress: 7.4% Elapsed: 2:25:15 Gen_loss: 2.785 Dis_loss: 2.277 Cls_loss: 3.024 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:52:33 > Step:   7500 Progress: 7.5% Elapsed: 2:27:03 Gen_loss: 3.399 Dis_loss: 2.179 Cls_loss: 3.02 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:54:19 > Step:   7600 Progress: 7.6% Elapsed: 2:28:49 Gen_loss: 3.056 Dis_loss: 2.202 Cls_loss: 3.04 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:56:06 > Step:   7700 Progress: 7.7% Elapsed: 2:30:36 Gen_loss: 2.187 Dis_loss: 2.705 Cls_loss: 3.173 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:57:52 > Step:   7800 Progress: 7.8% Elapsed: 2:32:22 Gen_loss: 2.582 Dis_loss: 2.249 Cls_loss: 2.988 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 19:59:40 > Step:   7900 Progress: 7.9% Elapsed: 2:34:10 Gen_loss: 2.946 Dis_loss: 2.624 Cls_loss: 3.169 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:01:27 > Step:   8000 Progress: 8.0% Elapsed: 2:35:56 Gen_loss: 3.226 Dis_loss: 2.571 Cls_loss: 3.129 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:01:27 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 20:01:27 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_8000.png\n",
            "[INFO] 2022-01-15 20:01:27 > Start Evaluation (8000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 20:01:27 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:14<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 20:05:41 > Inception score (Step: 8000, 50000 generated images): 7.736436367034912\n",
            "[INFO] 2022-01-15 20:05:55 > FID score (Step: 8000, Using train moments): 31.948110043009308\n",
            "[INFO] 2022-01-15 20:05:55 > Best FID score (Step: 4000, Using train moments): 28.494961568868064\n",
            "[INFO] 2022-01-15 20:05:56 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 20:07:42 > Step:   8100 Progress: 8.1% Elapsed: 2:42:12 Gen_loss: 2.699 Dis_loss: 2.255 Cls_loss: 3.056 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:09:30 > Step:   8200 Progress: 8.2% Elapsed: 2:44:00 Gen_loss: 2.368 Dis_loss: 2.36 Cls_loss: 3.089 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:11:17 > Step:   8300 Progress: 8.3% Elapsed: 2:45:46 Gen_loss: 3.278 Dis_loss: 2.317 Cls_loss: 3.178 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:13:03 > Step:   8400 Progress: 8.4% Elapsed: 2:47:33 Gen_loss: 2.677 Dis_loss: 2.201 Cls_loss: 3.07 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:14:50 > Step:   8500 Progress: 8.5% Elapsed: 2:49:19 Gen_loss: 2.839 Dis_loss: 2.288 Cls_loss: 3.138 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:16:37 > Step:   8600 Progress: 8.6% Elapsed: 2:51:07 Gen_loss: 3.239 Dis_loss: 2.131 Cls_loss: 3.067 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:18:24 > Step:   8700 Progress: 8.7% Elapsed: 2:52:54 Gen_loss: 2.746 Dis_loss: 2.345 Cls_loss: 3.114 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:20:10 > Step:   8800 Progress: 8.8% Elapsed: 2:54:40 Gen_loss: 2.84 Dis_loss: 2.214 Cls_loss: 2.973 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:21:58 > Step:   8900 Progress: 8.9% Elapsed: 2:56:28 Gen_loss: 2.539 Dis_loss: 2.107 Cls_loss: 3.13 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:23:45 > Step:   9000 Progress: 9.0% Elapsed: 2:58:14 Gen_loss: 1.779 Dis_loss: 2.417 Cls_loss: 3.065 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:25:31 > Step:   9100 Progress: 9.1% Elapsed: 3:00:01 Gen_loss: 2.319 Dis_loss: 2.114 Cls_loss: 2.965 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:27:17 > Step:   9200 Progress: 9.2% Elapsed: 3:01:47 Gen_loss: 1.836 Dis_loss: 2.287 Cls_loss: 3.04 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:29:05 > Step:   9300 Progress: 9.3% Elapsed: 3:03:35 Gen_loss: 2.91 Dis_loss: 2.121 Cls_loss: 3.11 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:30:52 > Step:   9400 Progress: 9.4% Elapsed: 3:05:21 Gen_loss: 2.433 Dis_loss: 2.201 Cls_loss: 3.059 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:32:38 > Step:   9500 Progress: 9.5% Elapsed: 3:07:08 Gen_loss: 2.531 Dis_loss: 2.55 Cls_loss: 3.073 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:34:26 > Step:   9600 Progress: 9.6% Elapsed: 3:08:56 Gen_loss: 2.829 Dis_loss: 2.264 Cls_loss: 3.103 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:36:12 > Step:   9700 Progress: 9.7% Elapsed: 3:10:42 Gen_loss: 2.992 Dis_loss: 2.173 Cls_loss: 3.017 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:37:59 > Step:   9800 Progress: 9.8% Elapsed: 3:12:29 Gen_loss: 2.208 Dis_loss: 2.277 Cls_loss: 3.022 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:39:45 > Step:   9900 Progress: 9.9% Elapsed: 3:14:15 Gen_loss: 2.361 Dis_loss: 2.267 Cls_loss: 3.041 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:41:33 > Step:  10000 Progress: 10.0% Elapsed: 3:16:03 Gen_loss: 2.231 Dis_loss: 2.248 Cls_loss: 3.151 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:41:33 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 20:41:33 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_10000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 20:41:33 > Start Evaluation (10000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 20:41:33 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:14<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 20:45:48 > Inception score (Step: 10000, 50000 generated images): 7.758829593658447\n",
            "[INFO] 2022-01-15 20:46:02 > FID score (Step: 10000, Using train moments): 31.732649829013496\n",
            "[INFO] 2022-01-15 20:46:02 > Best FID score (Step: 4000, Using train moments): 28.494961568868064\n",
            "[INFO] 2022-01-15 20:46:02 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 20:47:49 > Step:  10100 Progress: 10.1% Elapsed: 3:22:19 Gen_loss: 2.378 Dis_loss: 2.205 Cls_loss: 2.992 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:49:36 > Step:  10200 Progress: 10.2% Elapsed: 3:24:05 Gen_loss: 2.737 Dis_loss: 2.021 Cls_loss: 2.987 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:51:23 > Step:  10300 Progress: 10.3% Elapsed: 3:25:53 Gen_loss: 2.974 Dis_loss: 2.191 Cls_loss: 2.946 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:53:10 > Step:  10400 Progress: 10.4% Elapsed: 3:27:40 Gen_loss: 2.606 Dis_loss: 2.248 Cls_loss: 2.978 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:54:56 > Step:  10500 Progress: 10.5% Elapsed: 3:29:26 Gen_loss: 3.201 Dis_loss: 1.997 Cls_loss: 2.925 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:56:43 > Step:  10600 Progress: 10.6% Elapsed: 3:31:13 Gen_loss: 3.145 Dis_loss: 2.308 Cls_loss: 3.039 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 20:58:31 > Step:  10700 Progress: 10.7% Elapsed: 3:33:00 Gen_loss: 2.116 Dis_loss: 2.307 Cls_loss: 3.031 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:00:17 > Step:  10800 Progress: 10.8% Elapsed: 3:34:47 Gen_loss: 3.125 Dis_loss: 2.098 Cls_loss: 2.947 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:02:04 > Step:  10900 Progress: 10.9% Elapsed: 3:36:34 Gen_loss: 3.35 Dis_loss: 2.505 Cls_loss: 3.08 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:03:52 > Step:  11000 Progress: 11.0% Elapsed: 3:38:21 Gen_loss: 3.09 Dis_loss: 2.071 Cls_loss: 3.034 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:05:38 > Step:  11100 Progress: 11.1% Elapsed: 3:40:08 Gen_loss: 2.23 Dis_loss: 2.243 Cls_loss: 2.991 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:07:24 > Step:  11200 Progress: 11.2% Elapsed: 3:41:54 Gen_loss: 2.482 Dis_loss: 2.225 Cls_loss: 2.936 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:09:11 > Step:  11300 Progress: 11.3% Elapsed: 3:43:41 Gen_loss: 2.628 Dis_loss: 2.045 Cls_loss: 2.938 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:10:58 > Step:  11400 Progress: 11.4% Elapsed: 3:45:28 Gen_loss: 3.472 Dis_loss: 2.378 Cls_loss: 2.98 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:12:45 > Step:  11500 Progress: 11.5% Elapsed: 3:47:15 Gen_loss: 2.513 Dis_loss: 2.244 Cls_loss: 3.019 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:14:31 > Step:  11600 Progress: 11.6% Elapsed: 3:49:01 Gen_loss: 2.645 Dis_loss: 2.15 Cls_loss: 2.987 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:16:18 > Step:  11700 Progress: 11.7% Elapsed: 3:50:48 Gen_loss: 2.258 Dis_loss: 2.096 Cls_loss: 2.994 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:18:06 > Step:  11800 Progress: 11.8% Elapsed: 3:52:35 Gen_loss: 2.498 Dis_loss: 2.093 Cls_loss: 2.946 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:19:52 > Step:  11900 Progress: 11.9% Elapsed: 3:54:22 Gen_loss: 2.58 Dis_loss: 1.977 Cls_loss: 2.997 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:21:38 > Step:  12000 Progress: 12.0% Elapsed: 3:56:08 Gen_loss: 3.471 Dis_loss: 2.48 Cls_loss: 2.997 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:21:38 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 21:21:39 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_12000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 21:21:39 > Start Evaluation (12000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 21:21:39 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 21:25:53 > Inception score (Step: 12000, 50000 generated images): 7.784091472625732\n",
            "[INFO] 2022-01-15 21:26:07 > FID score (Step: 12000, Using train moments): 30.24157025042399\n",
            "[INFO] 2022-01-15 21:26:07 > Best FID score (Step: 4000, Using train moments): 28.494961568868064\n",
            "[INFO] 2022-01-15 21:26:07 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 21:27:55 > Step:  12100 Progress: 12.1% Elapsed: 4:02:24 Gen_loss: 2.506 Dis_loss: 2.207 Cls_loss: 2.972 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:29:41 > Step:  12200 Progress: 12.2% Elapsed: 4:04:11 Gen_loss: 3.251 Dis_loss: 2.058 Cls_loss: 2.967 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:31:28 > Step:  12300 Progress: 12.3% Elapsed: 4:05:57 Gen_loss: 3.423 Dis_loss: 2.431 Cls_loss: 2.978 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:33:14 > Step:  12400 Progress: 12.4% Elapsed: 4:07:44 Gen_loss: 2.719 Dis_loss: 2.308 Cls_loss: 3.046 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:35:02 > Step:  12500 Progress: 12.5% Elapsed: 4:09:32 Gen_loss: 2.752 Dis_loss: 2.197 Cls_loss: 3.043 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:36:48 > Step:  12600 Progress: 12.6% Elapsed: 4:11:18 Gen_loss: 3.479 Dis_loss: 2.168 Cls_loss: 3.052 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:38:35 > Step:  12700 Progress: 12.7% Elapsed: 4:13:04 Gen_loss: 2.342 Dis_loss: 2.042 Cls_loss: 2.985 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:40:22 > Step:  12800 Progress: 12.8% Elapsed: 4:14:52 Gen_loss: 1.71 Dis_loss: 2.205 Cls_loss: 2.932 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:42:09 > Step:  12900 Progress: 12.9% Elapsed: 4:16:38 Gen_loss: 2.089 Dis_loss: 2.203 Cls_loss: 2.976 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:43:55 > Step:  13000 Progress: 13.0% Elapsed: 4:18:25 Gen_loss: 2.328 Dis_loss: 2.01 Cls_loss: 2.927 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:45:42 > Step:  13100 Progress: 13.1% Elapsed: 4:20:11 Gen_loss: 2.84 Dis_loss: 2.142 Cls_loss: 2.973 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:47:29 > Step:  13200 Progress: 13.2% Elapsed: 4:21:59 Gen_loss: 2.208 Dis_loss: 2.301 Cls_loss: 3.008 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:49:15 > Step:  13300 Progress: 13.3% Elapsed: 4:23:45 Gen_loss: 2.37 Dis_loss: 2.242 Cls_loss: 2.993 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:51:02 > Step:  13400 Progress: 13.4% Elapsed: 4:25:31 Gen_loss: 2.445 Dis_loss: 2.169 Cls_loss: 3.012 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:52:49 > Step:  13500 Progress: 13.5% Elapsed: 4:27:19 Gen_loss: 3.325 Dis_loss: 2.167 Cls_loss: 2.974 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:54:36 > Step:  13600 Progress: 13.6% Elapsed: 4:29:05 Gen_loss: 3.489 Dis_loss: 2.144 Cls_loss: 2.955 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:56:22 > Step:  13700 Progress: 13.7% Elapsed: 4:30:52 Gen_loss: 2.377 Dis_loss: 2.12 Cls_loss: 3.011 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:58:08 > Step:  13800 Progress: 13.8% Elapsed: 4:32:38 Gen_loss: 2.846 Dis_loss: 2.11 Cls_loss: 3.008 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 21:59:55 > Step:  13900 Progress: 13.9% Elapsed: 4:34:25 Gen_loss: 3.052 Dis_loss: 2.058 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:01:42 > Step:  14000 Progress: 14.0% Elapsed: 4:36:12 Gen_loss: 2.647 Dis_loss: 2.043 Cls_loss: 3.048 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:01:42 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 22:01:42 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_14000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 22:01:42 > Start Evaluation (14000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 22:01:42 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 22:05:56 > Inception score (Step: 14000, 50000 generated images): 7.8712897300720215\n",
            "[INFO] 2022-01-15 22:06:10 > FID score (Step: 14000, Using train moments): 27.6023061482407\n",
            "[INFO] 2022-01-15 22:06:10 > Best FID score (Step: 14000, Using train moments): 27.6023061482407\n",
            "[INFO] 2022-01-15 22:06:11 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 22:07:57 > Step:  14100 Progress: 14.1% Elapsed: 4:42:27 Gen_loss: 2.976 Dis_loss: 2.157 Cls_loss: 3.029 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:09:44 > Step:  14200 Progress: 14.2% Elapsed: 4:44:14 Gen_loss: 3.724 Dis_loss: 2.09 Cls_loss: 2.963 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:11:31 > Step:  14300 Progress: 14.3% Elapsed: 4:46:00 Gen_loss: 2.703 Dis_loss: 2.059 Cls_loss: 2.96 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:13:17 > Step:  14400 Progress: 14.4% Elapsed: 4:47:47 Gen_loss: 2.095 Dis_loss: 2.206 Cls_loss: 2.959 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:15:03 > Step:  14500 Progress: 14.5% Elapsed: 4:49:33 Gen_loss: 2.267 Dis_loss: 2.196 Cls_loss: 2.936 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:16:50 > Step:  14600 Progress: 14.6% Elapsed: 4:51:20 Gen_loss: 2.276 Dis_loss: 2.192 Cls_loss: 2.993 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:18:37 > Step:  14700 Progress: 14.7% Elapsed: 4:53:06 Gen_loss: 2.52 Dis_loss: 1.994 Cls_loss: 2.914 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:20:23 > Step:  14800 Progress: 14.8% Elapsed: 4:54:52 Gen_loss: 3.233 Dis_loss: 2.278 Cls_loss: 2.978 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:22:10 > Step:  14900 Progress: 14.9% Elapsed: 4:56:40 Gen_loss: 2.197 Dis_loss: 2.197 Cls_loss: 2.962 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:23:56 > Step:  15000 Progress: 15.0% Elapsed: 4:58:26 Gen_loss: 2.935 Dis_loss: 2.054 Cls_loss: 3.005 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:25:43 > Step:  15100 Progress: 15.1% Elapsed: 5:00:12 Gen_loss: 2.708 Dis_loss: 2.124 Cls_loss: 2.958 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:27:29 > Step:  15200 Progress: 15.2% Elapsed: 5:01:59 Gen_loss: 2.826 Dis_loss: 2.101 Cls_loss: 2.933 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:29:17 > Step:  15300 Progress: 15.3% Elapsed: 5:03:46 Gen_loss: 2.868 Dis_loss: 2.121 Cls_loss: 3.039 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:31:03 > Step:  15400 Progress: 15.4% Elapsed: 5:05:33 Gen_loss: 2.357 Dis_loss: 2.136 Cls_loss: 2.972 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:32:49 > Step:  15500 Progress: 15.5% Elapsed: 5:07:19 Gen_loss: 3.356 Dis_loss: 2.109 Cls_loss: 2.938 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:34:36 > Step:  15600 Progress: 15.6% Elapsed: 5:09:05 Gen_loss: 2.759 Dis_loss: 2.208 Cls_loss: 2.926 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:36:23 > Step:  15700 Progress: 15.7% Elapsed: 5:10:53 Gen_loss: 3.291 Dis_loss: 2.197 Cls_loss: 2.906 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:38:09 > Step:  15800 Progress: 15.8% Elapsed: 5:12:39 Gen_loss: 2.55 Dis_loss: 2.166 Cls_loss: 2.949 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:39:56 > Step:  15900 Progress: 15.9% Elapsed: 5:14:25 Gen_loss: 3.312 Dis_loss: 2.065 Cls_loss: 2.968 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:41:43 > Step:  16000 Progress: 16.0% Elapsed: 5:16:13 Gen_loss: 1.78 Dis_loss: 2.23 Cls_loss: 2.962 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:41:43 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 22:41:43 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_16000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 22:41:43 > Start Evaluation (16000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 22:41:43 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 22:45:57 > Inception score (Step: 16000, 50000 generated images): 8.096086502075195\n",
            "[INFO] 2022-01-15 22:46:11 > FID score (Step: 16000, Using train moments): 24.56754132610496\n",
            "[INFO] 2022-01-15 22:46:11 > Best FID score (Step: 16000, Using train moments): 24.56754132610496\n",
            "[INFO] 2022-01-15 22:46:11 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 22:47:57 > Step:  16100 Progress: 16.1% Elapsed: 5:22:27 Gen_loss: 2.685 Dis_loss: 2.163 Cls_loss: 2.964 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:49:44 > Step:  16200 Progress: 16.2% Elapsed: 5:24:14 Gen_loss: 2.02 Dis_loss: 2.218 Cls_loss: 2.983 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:51:30 > Step:  16300 Progress: 16.3% Elapsed: 5:26:00 Gen_loss: 3.478 Dis_loss: 2.088 Cls_loss: 2.921 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:53:17 > Step:  16400 Progress: 16.4% Elapsed: 5:27:47 Gen_loss: 2.399 Dis_loss: 2.073 Cls_loss: 2.936 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:55:04 > Step:  16500 Progress: 16.5% Elapsed: 5:29:33 Gen_loss: 2.376 Dis_loss: 1.944 Cls_loss: 2.884 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:56:50 > Step:  16600 Progress: 16.6% Elapsed: 5:31:20 Gen_loss: 2.83 Dis_loss: 2.213 Cls_loss: 2.905 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 22:58:37 > Step:  16700 Progress: 16.7% Elapsed: 5:33:07 Gen_loss: 2.882 Dis_loss: 2.159 Cls_loss: 2.913 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:00:23 > Step:  16800 Progress: 16.8% Elapsed: 5:34:53 Gen_loss: 3.304 Dis_loss: 2.074 Cls_loss: 2.933 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:02:10 > Step:  16900 Progress: 16.9% Elapsed: 5:36:39 Gen_loss: 3.146 Dis_loss: 2.18 Cls_loss: 2.886 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:03:56 > Step:  17000 Progress: 17.0% Elapsed: 5:38:26 Gen_loss: 2.828 Dis_loss: 2.065 Cls_loss: 2.92 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:05:43 > Step:  17100 Progress: 17.1% Elapsed: 5:40:13 Gen_loss: 2.695 Dis_loss: 2.048 Cls_loss: 2.908 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:07:29 > Step:  17200 Progress: 17.2% Elapsed: 5:41:59 Gen_loss: 2.341 Dis_loss: 1.976 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:09:16 > Step:  17300 Progress: 17.3% Elapsed: 5:43:45 Gen_loss: 2.577 Dis_loss: 2.27 Cls_loss: 2.98 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:11:03 > Step:  17400 Progress: 17.4% Elapsed: 5:45:33 Gen_loss: 2.828 Dis_loss: 1.992 Cls_loss: 2.982 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:12:49 > Step:  17500 Progress: 17.5% Elapsed: 5:47:19 Gen_loss: 3.819 Dis_loss: 2.246 Cls_loss: 2.921 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:14:35 > Step:  17600 Progress: 17.6% Elapsed: 5:49:05 Gen_loss: 3.048 Dis_loss: 2.045 Cls_loss: 2.931 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:16:22 > Step:  17700 Progress: 17.7% Elapsed: 5:50:51 Gen_loss: 2.994 Dis_loss: 2.076 Cls_loss: 2.956 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:18:09 > Step:  17800 Progress: 17.8% Elapsed: 5:52:39 Gen_loss: 2.81 Dis_loss: 2.131 Cls_loss: 2.874 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:19:55 > Step:  17900 Progress: 17.9% Elapsed: 5:54:25 Gen_loss: 2.628 Dis_loss: 2.115 Cls_loss: 3.01 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:21:41 > Step:  18000 Progress: 18.0% Elapsed: 5:56:11 Gen_loss: 2.438 Dis_loss: 2.162 Cls_loss: 2.995 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:21:41 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-15 23:21:41 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_18000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-15 23:21:42 > Start Evaluation (18000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 23:21:42 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-15 23:25:55 > Inception score (Step: 18000, 50000 generated images): 8.326048851013184\n",
            "[INFO] 2022-01-15 23:26:09 > FID score (Step: 18000, Using train moments): 21.571747252791226\n",
            "[INFO] 2022-01-15 23:26:09 > Best FID score (Step: 18000, Using train moments): 21.571747252791226\n",
            "[INFO] 2022-01-15 23:26:10 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-15 23:27:57 > Step:  18100 Progress: 18.1% Elapsed: 6:02:27 Gen_loss: 2.262 Dis_loss: 2.228 Cls_loss: 2.892 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:29:44 > Step:  18200 Progress: 18.2% Elapsed: 6:04:13 Gen_loss: 3.165 Dis_loss: 2.03 Cls_loss: 3.028 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:31:30 > Step:  18300 Progress: 18.3% Elapsed: 6:06:00 Gen_loss: 2.253 Dis_loss: 2.144 Cls_loss: 2.973 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:33:16 > Step:  18400 Progress: 18.4% Elapsed: 6:07:46 Gen_loss: 3.21 Dis_loss: 1.952 Cls_loss: 2.913 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:35:03 > Step:  18500 Progress: 18.5% Elapsed: 6:09:33 Gen_loss: 3.101 Dis_loss: 1.979 Cls_loss: 2.914 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:36:50 > Step:  18600 Progress: 18.6% Elapsed: 6:11:19 Gen_loss: 3.325 Dis_loss: 2.437 Cls_loss: 2.948 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:38:36 > Step:  18700 Progress: 18.7% Elapsed: 6:13:06 Gen_loss: 2.127 Dis_loss: 2.031 Cls_loss: 2.953 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:40:23 > Step:  18800 Progress: 18.8% Elapsed: 6:14:53 Gen_loss: 2.27 Dis_loss: 2.322 Cls_loss: 2.955 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:42:09 > Step:  18900 Progress: 18.9% Elapsed: 6:16:39 Gen_loss: 3.099 Dis_loss: 1.967 Cls_loss: 2.873 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:43:56 > Step:  19000 Progress: 19.0% Elapsed: 6:18:25 Gen_loss: 2.793 Dis_loss: 2.112 Cls_loss: 2.941 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:45:42 > Step:  19100 Progress: 19.1% Elapsed: 6:20:11 Gen_loss: 2.573 Dis_loss: 2.163 Cls_loss: 2.96 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:47:29 > Step:  19200 Progress: 19.2% Elapsed: 6:21:59 Gen_loss: 2.908 Dis_loss: 2.142 Cls_loss: 2.97 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:49:15 > Step:  19300 Progress: 19.3% Elapsed: 6:23:45 Gen_loss: 2.981 Dis_loss: 2.069 Cls_loss: 2.935 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:51:01 > Step:  19400 Progress: 19.4% Elapsed: 6:25:31 Gen_loss: 2.607 Dis_loss: 2.225 Cls_loss: 2.943 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:52:47 > Step:  19500 Progress: 19.5% Elapsed: 6:27:17 Gen_loss: 3.18 Dis_loss: 2.011 Cls_loss: 2.945 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:54:35 > Step:  19600 Progress: 19.6% Elapsed: 6:29:05 Gen_loss: 2.729 Dis_loss: 1.923 Cls_loss: 2.938 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:56:21 > Step:  19700 Progress: 19.7% Elapsed: 6:30:51 Gen_loss: 2.279 Dis_loss: 2.019 Cls_loss: 3.0 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:58:07 > Step:  19800 Progress: 19.8% Elapsed: 6:32:37 Gen_loss: 2.981 Dis_loss: 2.091 Cls_loss: 2.986 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-15 23:59:55 > Step:  19900 Progress: 19.9% Elapsed: 6:34:24 Gen_loss: 2.87 Dis_loss: 2.053 Cls_loss: 2.895 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:01:41 > Step:  20000 Progress: 20.0% Elapsed: 6:36:10 Gen_loss: 3.446 Dis_loss: 2.684 Cls_loss: 2.906 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:01:41 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-16 00:01:41 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_20000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-16 00:01:41 > Start Evaluation (20000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-16 00:01:41 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-16 00:05:55 > Inception score (Step: 20000, 50000 generated images): 8.51126480102539\n",
            "[INFO] 2022-01-16 00:06:09 > FID score (Step: 20000, Using train moments): 18.949786192626277\n",
            "[INFO] 2022-01-16 00:06:09 > Best FID score (Step: 20000, Using train moments): 18.949786192626277\n",
            "[INFO] 2022-01-16 00:06:10 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-16 00:07:56 > Step:  20100 Progress: 20.1% Elapsed: 6:42:26 Gen_loss: 2.589 Dis_loss: 2.076 Cls_loss: 2.871 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:09:42 > Step:  20200 Progress: 20.2% Elapsed: 6:44:12 Gen_loss: 1.97 Dis_loss: 2.326 Cls_loss: 2.898 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:11:29 > Step:  20300 Progress: 20.3% Elapsed: 6:45:59 Gen_loss: 3.426 Dis_loss: 2.038 Cls_loss: 2.923 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:13:16 > Step:  20400 Progress: 20.4% Elapsed: 6:47:45 Gen_loss: 3.223 Dis_loss: 2.146 Cls_loss: 2.942 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:15:02 > Step:  20500 Progress: 20.5% Elapsed: 6:49:32 Gen_loss: 3.413 Dis_loss: 2.187 Cls_loss: 2.916 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:16:49 > Step:  20600 Progress: 20.6% Elapsed: 6:51:19 Gen_loss: 3.116 Dis_loss: 1.972 Cls_loss: 2.942 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:18:35 > Step:  20700 Progress: 20.7% Elapsed: 6:53:05 Gen_loss: 3.069 Dis_loss: 2.147 Cls_loss: 2.893 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:20:21 > Step:  20800 Progress: 20.8% Elapsed: 6:54:51 Gen_loss: 3.646 Dis_loss: 2.573 Cls_loss: 2.927 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:22:08 > Step:  20900 Progress: 20.9% Elapsed: 6:56:37 Gen_loss: 2.568 Dis_loss: 2.07 Cls_loss: 2.891 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:23:55 > Step:  21000 Progress: 21.0% Elapsed: 6:58:25 Gen_loss: 3.123 Dis_loss: 2.022 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:25:41 > Step:  21100 Progress: 21.1% Elapsed: 7:00:11 Gen_loss: 3.188 Dis_loss: 2.031 Cls_loss: 2.896 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:27:28 > Step:  21200 Progress: 21.2% Elapsed: 7:01:57 Gen_loss: 1.834 Dis_loss: 2.122 Cls_loss: 2.898 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:29:15 > Step:  21300 Progress: 21.3% Elapsed: 7:03:45 Gen_loss: 2.46 Dis_loss: 2.022 Cls_loss: 2.878 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:31:01 > Step:  21400 Progress: 21.4% Elapsed: 7:05:31 Gen_loss: 3.031 Dis_loss: 2.049 Cls_loss: 2.882 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:32:47 > Step:  21500 Progress: 21.5% Elapsed: 7:07:17 Gen_loss: 2.657 Dis_loss: 2.06 Cls_loss: 2.898 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:34:34 > Step:  21600 Progress: 21.6% Elapsed: 7:09:04 Gen_loss: 2.562 Dis_loss: 2.121 Cls_loss: 2.959 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:36:21 > Step:  21700 Progress: 21.7% Elapsed: 7:10:51 Gen_loss: 2.567 Dis_loss: 2.068 Cls_loss: 2.915 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:38:07 > Step:  21800 Progress: 21.8% Elapsed: 7:12:37 Gen_loss: 3.352 Dis_loss: 2.349 Cls_loss: 2.901 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:39:54 > Step:  21900 Progress: 21.9% Elapsed: 7:14:23 Gen_loss: 2.577 Dis_loss: 2.057 Cls_loss: 2.94 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:41:41 > Step:  22000 Progress: 22.0% Elapsed: 7:16:11 Gen_loss: 2.817 Dis_loss: 2.145 Cls_loss: 2.876 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:41:41 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-16 00:41:41 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_22000.png\n",
            "[INFO] 2022-01-16 00:41:41 > Start Evaluation (22000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-16 00:41:41 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-16 00:45:55 > Inception score (Step: 22000, 50000 generated images): 8.616464614868164\n",
            "[INFO] 2022-01-16 00:46:09 > FID score (Step: 22000, Using train moments): 16.655526918290093\n",
            "[INFO] 2022-01-16 00:46:09 > Best FID score (Step: 22000, Using train moments): 16.655526918290093\n",
            "[INFO] 2022-01-16 00:46:10 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-16 00:47:56 > Step:  22100 Progress: 22.1% Elapsed: 7:22:26 Gen_loss: 2.604 Dis_loss: 1.958 Cls_loss: 2.884 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:49:42 > Step:  22200 Progress: 22.2% Elapsed: 7:24:12 Gen_loss: 3.491 Dis_loss: 2.045 Cls_loss: 2.917 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:51:28 > Step:  22300 Progress: 22.3% Elapsed: 7:25:58 Gen_loss: 3.676 Dis_loss: 2.096 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:53:15 > Step:  22400 Progress: 22.4% Elapsed: 7:27:45 Gen_loss: 2.498 Dis_loss: 1.958 Cls_loss: 2.899 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:55:01 > Step:  22500 Progress: 22.5% Elapsed: 7:29:31 Gen_loss: 2.858 Dis_loss: 2.002 Cls_loss: 2.902 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:56:47 > Step:  22600 Progress: 22.6% Elapsed: 7:31:17 Gen_loss: 3.168 Dis_loss: 1.998 Cls_loss: 2.958 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 00:58:35 > Step:  22700 Progress: 22.7% Elapsed: 7:33:05 Gen_loss: 2.556 Dis_loss: 2.04 Cls_loss: 2.905 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:00:21 > Step:  22800 Progress: 22.8% Elapsed: 7:34:51 Gen_loss: 2.685 Dis_loss: 1.98 Cls_loss: 2.928 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:02:07 > Step:  22900 Progress: 22.9% Elapsed: 7:36:37 Gen_loss: 2.429 Dis_loss: 2.001 Cls_loss: 2.972 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:03:53 > Step:  23000 Progress: 23.0% Elapsed: 7:38:23 Gen_loss: 2.704 Dis_loss: 2.216 Cls_loss: 2.914 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:05:40 > Step:  23100 Progress: 23.1% Elapsed: 7:40:10 Gen_loss: 3.599 Dis_loss: 2.224 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:07:26 > Step:  23200 Progress: 23.2% Elapsed: 7:41:56 Gen_loss: 3.296 Dis_loss: 2.013 Cls_loss: 2.952 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:09:13 > Step:  23300 Progress: 23.3% Elapsed: 7:43:42 Gen_loss: 2.917 Dis_loss: 2.073 Cls_loss: 2.933 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:10:59 > Step:  23400 Progress: 23.4% Elapsed: 7:45:29 Gen_loss: 2.893 Dis_loss: 2.051 Cls_loss: 2.926 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:12:46 > Step:  23500 Progress: 23.5% Elapsed: 7:47:16 Gen_loss: 2.701 Dis_loss: 2.058 Cls_loss: 2.954 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:14:32 > Step:  23600 Progress: 23.6% Elapsed: 7:49:02 Gen_loss: 2.262 Dis_loss: 2.301 Cls_loss: 2.934 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:16:18 > Step:  23700 Progress: 23.7% Elapsed: 7:50:48 Gen_loss: 3.584 Dis_loss: 2.162 Cls_loss: 2.996 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:18:06 > Step:  23800 Progress: 23.8% Elapsed: 7:52:36 Gen_loss: 2.786 Dis_loss: 1.986 Cls_loss: 2.999 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:19:52 > Step:  23900 Progress: 23.9% Elapsed: 7:54:22 Gen_loss: 3.127 Dis_loss: 2.083 Cls_loss: 2.871 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:21:38 > Step:  24000 Progress: 24.0% Elapsed: 7:56:08 Gen_loss: 3.503 Dis_loss: 2.023 Cls_loss: 2.902 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:21:38 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-16 01:21:38 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_24000.png\n",
            "[INFO] 2022-01-16 01:21:38 > Start Evaluation (24000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-16 01:21:38 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-16 01:25:52 > Inception score (Step: 24000, 50000 generated images): 8.795934677124023\n",
            "[INFO] 2022-01-16 01:26:06 > FID score (Step: 24000, Using train moments): 14.924278825530735\n",
            "[INFO] 2022-01-16 01:26:06 > Best FID score (Step: 24000, Using train moments): 14.924278825530735\n",
            "[INFO] 2022-01-16 01:26:07 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-16 01:27:53 > Step:  24100 Progress: 24.1% Elapsed: 8:02:23 Gen_loss: 3.038 Dis_loss: 1.959 Cls_loss: 2.886 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:29:40 > Step:  24200 Progress: 24.2% Elapsed: 8:04:10 Gen_loss: 2.984 Dis_loss: 2.215 Cls_loss: 2.93 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:31:26 > Step:  24300 Progress: 24.3% Elapsed: 8:05:56 Gen_loss: 3.123 Dis_loss: 1.999 Cls_loss: 2.919 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:33:12 > Step:  24400 Progress: 24.4% Elapsed: 8:07:42 Gen_loss: 2.481 Dis_loss: 1.885 Cls_loss: 2.913 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:35:00 > Step:  24500 Progress: 24.5% Elapsed: 8:09:30 Gen_loss: 2.479 Dis_loss: 1.982 Cls_loss: 2.888 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:36:46 > Step:  24600 Progress: 24.6% Elapsed: 8:11:16 Gen_loss: 2.137 Dis_loss: 2.001 Cls_loss: 2.888 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:38:32 > Step:  24700 Progress: 24.7% Elapsed: 8:13:02 Gen_loss: 3.138 Dis_loss: 1.955 Cls_loss: 2.892 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:40:18 > Step:  24800 Progress: 24.8% Elapsed: 8:14:48 Gen_loss: 3.059 Dis_loss: 2.257 Cls_loss: 2.904 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:42:05 > Step:  24900 Progress: 24.9% Elapsed: 8:16:35 Gen_loss: 2.791 Dis_loss: 2.102 Cls_loss: 2.935 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:43:52 > Step:  25000 Progress: 25.0% Elapsed: 8:18:22 Gen_loss: 2.541 Dis_loss: 2.125 Cls_loss: 2.897 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:45:38 > Step:  25100 Progress: 25.1% Elapsed: 8:20:08 Gen_loss: 2.189 Dis_loss: 2.045 Cls_loss: 2.865 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:47:25 > Step:  25200 Progress: 25.2% Elapsed: 8:21:55 Gen_loss: 2.671 Dis_loss: 1.963 Cls_loss: 2.909 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:49:11 > Step:  25300 Progress: 25.3% Elapsed: 8:23:41 Gen_loss: 3.546 Dis_loss: 2.114 Cls_loss: 2.864 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:50:57 > Step:  25400 Progress: 25.4% Elapsed: 8:25:27 Gen_loss: 2.691 Dis_loss: 1.973 Cls_loss: 2.863 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:52:44 > Step:  25500 Progress: 25.5% Elapsed: 8:27:14 Gen_loss: 3.282 Dis_loss: 2.039 Cls_loss: 2.903 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:54:31 > Step:  25600 Progress: 25.6% Elapsed: 8:29:01 Gen_loss: 2.582 Dis_loss: 1.997 Cls_loss: 2.876 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:56:18 > Step:  25700 Progress: 25.7% Elapsed: 8:30:47 Gen_loss: 2.634 Dis_loss: 2.022 Cls_loss: 2.91 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:58:04 > Step:  25800 Progress: 25.8% Elapsed: 8:32:34 Gen_loss: 2.51 Dis_loss: 2.1 Cls_loss: 2.927 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 01:59:51 > Step:  25900 Progress: 25.9% Elapsed: 8:34:21 Gen_loss: 3.419 Dis_loss: 1.897 Cls_loss: 2.908 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:01:38 > Step:  26000 Progress: 26.0% Elapsed: 8:36:07 Gen_loss: 3.266 Dis_loss: 2.064 Cls_loss: 2.924 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:01:38 > Visualize (num_rows x 8) fake image canvans.\n",
            "[INFO] 2022-01-16 02:01:38 > Save image canvas to model/figures/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/generated_canvas_26000.png\n",
            "  0% 0/391 [00:00<?, ?it/s][INFO] 2022-01-16 02:01:38 > Start Evaluation (26000 Step): CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-16 02:01:38 > generate images and stack features (50000 images).\n",
            "100% 391/391 [04:13<00:00,  1.54it/s]\n",
            "[INFO] 2022-01-16 02:05:52 > Inception score (Step: 26000, 50000 generated images): 8.90042495727539\n",
            "[INFO] 2022-01-16 02:06:05 > FID score (Step: 26000, Using train moments): 13.644141240997556\n",
            "[INFO] 2022-01-16 02:06:05 > Best FID score (Step: 26000, Using train moments): 13.644141240997556\n",
            "[INFO] 2022-01-16 02:06:06 > Save model to model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59\n",
            "[INFO] 2022-01-16 02:07:52 > Step:  26100 Progress: 26.1% Elapsed: 8:42:22 Gen_loss: 2.645 Dis_loss: 2.008 Cls_loss: 2.913 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:09:39 > Step:  26200 Progress: 26.2% Elapsed: 8:44:08 Gen_loss: 2.917 Dis_loss: 1.947 Cls_loss: 2.939 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:11:26 > Step:  26300 Progress: 26.3% Elapsed: 8:45:56 Gen_loss: 2.798 Dis_loss: 1.966 Cls_loss: 2.9 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:13:12 > Step:  26400 Progress: 26.4% Elapsed: 8:47:42 Gen_loss: 3.325 Dis_loss: 2.322 Cls_loss: 2.94 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:14:58 > Step:  26500 Progress: 26.5% Elapsed: 8:49:28 Gen_loss: 1.504 Dis_loss: 2.544 Cls_loss: 2.88 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:16:45 > Step:  26600 Progress: 26.6% Elapsed: 8:51:15 Gen_loss: 3.204 Dis_loss: 1.986 Cls_loss: 2.983 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:18:31 > Step:  26700 Progress: 26.7% Elapsed: 8:53:01 Gen_loss: 2.708 Dis_loss: 1.988 Cls_loss: 2.889 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:20:18 > Step:  26800 Progress: 26.8% Elapsed: 8:54:47 Gen_loss: 2.61 Dis_loss: 2.007 Cls_loss: 2.967 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:22:04 > Step:  26900 Progress: 26.9% Elapsed: 8:56:34 Gen_loss: 2.881 Dis_loss: 2.19 Cls_loss: 2.884 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:23:51 > Step:  27000 Progress: 27.0% Elapsed: 8:58:21 Gen_loss: 3.225 Dis_loss: 2.113 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:25:37 > Step:  27100 Progress: 27.1% Elapsed: 9:00:07 Gen_loss: 3.2 Dis_loss: 2.194 Cls_loss: 2.877 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:27:23 > Step:  27200 Progress: 27.2% Elapsed: 9:01:53 Gen_loss: 2.209 Dis_loss: 2.081 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:29:09 > Step:  27300 Progress: 27.3% Elapsed: 9:03:39 Gen_loss: 2.172 Dis_loss: 2.363 Cls_loss: 2.912 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:30:57 > Step:  27400 Progress: 27.4% Elapsed: 9:05:26 Gen_loss: 3.132 Dis_loss: 2.008 Cls_loss: 2.923 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:32:43 > Step:  27500 Progress: 27.5% Elapsed: 9:07:13 Gen_loss: 2.409 Dis_loss: 2.036 Cls_loss: 2.897 Topk:  N/A ada_p: N/A \n",
            "[INFO] 2022-01-16 02:34:29 > Step:  27600 Progress: 27.6% Elapsed: 9:08:59 Gen_loss: 3.187 Dis_loss: 1.906 Cls_loss: 2.899 Topk:  N/A ada_p: N/A \n",
            "Traceback (most recent call last):\n",
            "  File \"src/main.py\", line 183, in <module>\n",
            "    hdf5_path=hdf5_path)\n",
            "  File \"/content/PyTorch-StudioGAN/src/loader.py\", line 339, in load_worker\n",
            "    gen_acml_loss = worker.train_generator(current_step=step)\n",
            "  File \"/content/PyTorch-StudioGAN/src/worker.py\", line 509, in train_generator\n",
            "    fake_cond_loss = self.cond_loss(**fake_dict)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/PyTorch-StudioGAN/src/utils/losses.py\", line 208, in forward\n",
            "    sim_matrix = self.remove_diag(sim_matrix/self.temperature)\n",
            "  File \"/content/PyTorch-StudioGAN/src/utils/losses.py\", line 195, in remove_diag\n",
            "    mask = (mask).type(torch.bool).to(self.master_rank)\n",
            "KeyboardInterrupt\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 403... (failed 255). Press ctrl-c to abort syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.0.0.conv2d0.weight_orig â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.0.0.conv2d1.weight_orig â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.0.0.conv2d2.weight_orig â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    Dis_blocks.1.0.conv1x1_attn.weight_orig â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Dis_blocks.1.0.conv1x1_g.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Dis_blocks.1.0.conv1x1_phi.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   Dis_blocks.1.0.conv1x1_theta.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.2.0.conv2d0.weight_orig â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.2.0.conv2d1.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.2.0.conv2d2.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.3.0.conv2d1.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.3.0.conv2d2.weight_orig â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.4.0.conv2d1.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.4.0.conv2d2.weight_orig â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  Dis_embedding.weight_orig â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Dis_linear1.weight_orig â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Dis_linear2.weight_orig â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                  FID score â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn1.bias.weight_orig â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn1.gain.weight_orig â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn2.bias.weight_orig â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn2.gain.weight_orig â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.0.0.conv2d0.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.0.0.conv2d1.weight_orig â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.0.0.conv2d2.weight_orig â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn1.bias.weight_orig â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn1.gain.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn2.bias.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn2.gain.weight_orig â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.1.0.conv2d0.weight_orig â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.1.0.conv2d1.weight_orig â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.1.0.conv2d2.weight_orig â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    Gen_blocks.2.0.conv1x1_attn.weight_orig â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Gen_blocks.2.0.conv1x1_g.weight_orig â–‚â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Gen_blocks.2.0.conv1x1_phi.weight_orig â–â–‚â–ƒâ–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   Gen_blocks.2.0.conv1x1_theta.weight_orig â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–…â–…â–…â–…â–…â–†â–†â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn1.bias.weight_orig â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn1.gain.weight_orig â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn2.bias.weight_orig â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn2.gain.weight_orig â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.3.0.conv2d0.weight_orig â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.3.0.conv2d1.weight_orig â–â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.3.0.conv2d2.weight_orig â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Gen_conv2d5.weight_orig â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Gen_linear0.weight_orig â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   IS score â–â–ƒâ–„â–ƒâ–„â–„â–„â–…â–†â–†â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   cls_loss â–ˆâ–‡â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   dis_loss â–ˆâ–†â–…â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   gen_loss â–‚â–ƒâ–…â–†â–‚â–‡â–…â–‡â–„â–ƒâ–†â–‡â–…â–â–ƒâ–‡â–„â–ˆâ–â–ˆâ–…â–‡â–…â–„â–‡â–†â–‡â–†â–…â–‡â–â–…â–„â–‡â–ˆâ–†â–…â–‡â–…â–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.0.0.conv2d0.weight_orig 1.87791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.0.0.conv2d1.weight_orig 1.45023\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.0.0.conv2d2.weight_orig 5.02473\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    Dis_blocks.1.0.conv1x1_attn.weight_orig 3.52914\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Dis_blocks.1.0.conv1x1_g.weight_orig 3.43674\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Dis_blocks.1.0.conv1x1_phi.weight_orig 2.07685\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   Dis_blocks.1.0.conv1x1_theta.weight_orig 2.39948\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.2.0.conv2d0.weight_orig 2.88587\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.2.0.conv2d1.weight_orig 4.35392\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.2.0.conv2d2.weight_orig 4.26309\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.3.0.conv2d1.weight_orig 4.19936\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.3.0.conv2d2.weight_orig 3.99377\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.4.0.conv2d1.weight_orig 3.67109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Dis_blocks.4.0.conv2d2.weight_orig 4.23626\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  Dis_embedding.weight_orig 2.91816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Dis_linear1.weight_orig 1.19167\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Dis_linear2.weight_orig 44.46753\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                  FID score 13.64414\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn1.bias.weight_orig 6.0379\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn1.gain.weight_orig 4.46904\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn2.bias.weight_orig 7.91761\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.0.0.bn2.gain.weight_orig 4.41591\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.0.0.conv2d0.weight_orig 3.80299\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.0.0.conv2d1.weight_orig 8.1595\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.0.0.conv2d2.weight_orig 11.08778\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn1.bias.weight_orig 9.09267\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn1.gain.weight_orig 4.69395\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn2.bias.weight_orig 10.40701\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.1.0.bn2.gain.weight_orig 4.93433\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.1.0.conv2d0.weight_orig 12.07076\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.1.0.conv2d1.weight_orig 11.22428\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.1.0.conv2d2.weight_orig 10.74891\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    Gen_blocks.2.0.conv1x1_attn.weight_orig 5.29438\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Gen_blocks.2.0.conv1x1_g.weight_orig 3.97039\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Gen_blocks.2.0.conv1x1_phi.weight_orig 2.58589\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   Gen_blocks.2.0.conv1x1_theta.weight_orig 2.73092\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn1.bias.weight_orig 6.30963\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn1.gain.weight_orig 3.16257\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn2.bias.weight_orig 6.33555\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        Gen_blocks.3.0.bn2.gain.weight_orig 2.94354\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.3.0.conv2d0.weight_orig 17.37413\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.3.0.conv2d1.weight_orig 13.20838\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Gen_blocks.3.0.conv2d2.weight_orig 13.41226\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Gen_conv2d5.weight_orig 3.0636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    Gen_linear0.weight_orig 4.45211\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   IS score 8.90042\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   cls_loss 2.89885\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   dis_loss 1.90616\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   gen_loss 3.18707\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCIFAR10-ReACGAN-train-2022_01_15_17_20_59\u001b[0m: \u001b[34mhttps://wandb.ai/kiritowu/PyTorch-StudioGAN-src/runs/2dzu2120\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: model/wandb/run-20220115_172526-2dzu2120/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r CIFAR10-REACGAN.zip model/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDzkhfY_xBur",
        "outputId": "bf773ff5-15dd-4a06-bf5f-4536b2fef44e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model/checkpoints/ (stored 0%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/ (stored 0%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/model=D-best-weights-step=26000.pth (deflated 8%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/model=G-current-weights-step=26000.pth (deflated 8%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/model=G-best-weights-step=26000.pth (deflated 8%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/model=D-current-weights-step=26000.pth (deflated 8%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/model=G_ema-best-weights-step=26000.pth (deflated 7%)\n",
            "  adding: model/checkpoints/CIFAR10-ReACGAN-train-2022_01_15_17_20_59/model=G_ema-current-weights-step=26000.pth (deflated 7%)\n"
          ]
        }
      ]
    }
  ]
}