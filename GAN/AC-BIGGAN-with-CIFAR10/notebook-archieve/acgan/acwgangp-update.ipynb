{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEyEnBV0YKOd",
        "outputId": "110885bd-890d-40c7-a829-8e6dbbd6dc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GAN'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 34 (delta 6), reused 28 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n",
            "/content/GAN\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/kiritowu/GAN.git\n",
        "%cd GAN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NJCeYXP4YKOg"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from models.utils import weights_init\n",
        "from models.acwgangp import Generator, Discriminator, calculate_gradient_penalty\n",
        "from utils.data import get_CIFAR10, _CIFAR_MEAN, _CIFAR_STD\n",
        "from utils.plot import plot_grid, inverseNormalize, classnames_from_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "A8d2n7TiYKOh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xRKatI9pYKOh"
      },
      "outputs": [],
      "source": [
        "hparams = dict(\n",
        "    batch_size=64,\n",
        "    latent_dim=100,\n",
        "    n_classes=10,\n",
        "    image_size=32,\n",
        "    channels=3,\n",
        "    lambda_cls=5,\n",
        "    lambda_gp=10,\n",
        "    train_d_times = 5,\n",
        "    train_g_times = 1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GSIGxoBYKOi",
        "outputId": "23644b73-6db8-40a0-b44f-3962f2c1fbc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar_data = get_CIFAR10(concatDataset=True)\n",
        "cifar_loader = data.DataLoader(\n",
        "    cifar_data, batch_size=hparams.get(\"batch_size\", 64), shuffle=True\n",
        ")\n",
        "cifar10_classnames = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iUg11AHAYKOj"
      },
      "outputs": [],
      "source": [
        "def train_one_batch_acwgan(\n",
        "    epoch: int,\n",
        "    data_loader: data.DataLoader,\n",
        "    generator: nn.Module,\n",
        "    discriminator: nn.Module,\n",
        "    aux_loss: nn.CrossEntropyLoss,\n",
        "    g_optimizer: optim.Adam,\n",
        "    d_optimizer: optim.Adam,\n",
        "    device: torch.device,\n",
        "    n_classes: int,\n",
        "    latent_dim: int,\n",
        "    train_d_times: int,\n",
        "    train_g_times: int,\n",
        "    **kwargs,\n",
        "):\n",
        "\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for real_imgs, real_labels in data_loader:\n",
        "        batch_size = real_imgs.shape[0]\n",
        "\n",
        "        real_imgs, real_labels = real_imgs.to(device), real_labels.to(device)\n",
        "\n",
        "        \"\"\"\n",
        "        Training of Discriminator\n",
        "        \"\"\"\n",
        "        for _ in range(train_d_times):\n",
        "            latent_space = torch.normal(\n",
        "                0, 1, (batch_size, latent_dim), device=device, requires_grad=False\n",
        "            )\n",
        "            gen_labels = torch.randint(\n",
        "                0, n_classes, (batch_size,), device=device, requires_grad=False\n",
        "            )\n",
        "            fake_imgs = generator(latent_space, gen_labels)\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            # Loss for real images\n",
        "            real_pred, real_aux = discriminator(real_imgs)\n",
        "            d_real_loss = -torch.mean(real_pred)\n",
        "\n",
        "            # Loss for fake images\n",
        "            fake_pred, fake_aux = discriminator(\n",
        "                fake_imgs\n",
        "                .detach() # Detach to not calculate gradient\n",
        "            )\n",
        "            d_fake_loss = torch.mean(fake_pred)\n",
        "\n",
        "            # Compute gradient penalty\n",
        "            gradient_penalty = calculate_gradient_penalty(\n",
        "                discriminator, real_imgs.data, fake_imgs.data, device\n",
        "            )\n",
        "\n",
        "            # Calculate Discriminator Loss\n",
        "            d_loss = (\n",
        "                d_real_loss\n",
        "                + d_fake_loss\n",
        "                + kwargs.get(\"lambda_cls\") *(aux_loss(real_aux, real_labels)+ aux_loss(fake_aux, gen_labels))/2\n",
        "                + kwargs.get(\"lambda_gp\") * gradient_penalty\n",
        "            )\n",
        "\n",
        "            # Calculate gradient to the loss and Update generator weights\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "        # Calculate Discriminator Auxillary Accuracy\n",
        "        pred = np.concatenate(\n",
        "            [real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0\n",
        "        )\n",
        "        gt = np.concatenate(\n",
        "            [real_labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0\n",
        "        )\n",
        "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
        "\n",
        "        \"\"\"\n",
        "        Training of Generator\n",
        "        \"\"\"\n",
        "        for _ in range(train_g_times):\n",
        "            g_optimizer.zero_grad()\n",
        "\n",
        "            # Generate fake image with Generator\n",
        "            fake_imgs = generator(latent_space, gen_labels)\n",
        "\n",
        "            # Get Adversarial and Auxillary(class) prediction from Discriminator\n",
        "            adversarial, pred_labels = discriminator(fake_imgs)\n",
        "\n",
        "            # Calculate Generator Loss\n",
        "            g_loss = -torch.mean(adversarial) + kwargs.get(\"lambda_cls\") * aux_loss(pred_labels, gen_labels)\n",
        "\n",
        "            # Calculate gradient to the loss and Update generator weights\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        \n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch}]\\tDLoss: {d_loss.cpu().item():.4f}\\tGLoss: {g_loss.cpu().item():.4f}\\tAuxAcc: {d_acc*100:.2f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gWeQL9V8YKOl"
      },
      "outputs": [],
      "source": [
        "def evaluate(generator: nn.Module, batch_size, latent_dim, n_classes, **kwargs):\n",
        "    latent_space = torch.normal(0, 1, (batch_size, latent_dim), device=device, requires_grad=False)\n",
        "    gen_labels = torch.randint(0, n_classes, (batch_size,), device=device, requires_grad=False)\n",
        "    imgs = generator(latent_space, gen_labels)\n",
        "    plot_grid(\n",
        "        imgs.cpu(),\n",
        "        labels=classnames_from_tensor(gen_labels.cpu(), cifar10_classnames),\n",
        "        inv_preprocessing=[partial(inverseNormalize, mean=_CIFAR_MEAN, std=_CIFAR_STD)],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9Lud-rsVYKOl"
      },
      "outputs": [],
      "source": [
        "epoch = 0\n",
        "generator = Generator(**hparams).to(device).apply(weights_init)\n",
        "discriminator = Discriminator(**hparams).to(device).apply(weights_init)\n",
        "aux_loss = nn.CrossEntropyLoss()\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.002, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMTx4-SFYKOm",
        "outputId": "91a1e557-781a-4c38-9610-c23409bff3e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(500):\n",
        "    train_one_batch_acwgan(\n",
        "        epoch,\n",
        "        cifar_loader,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        aux_loss,\n",
        "        g_optimizer,\n",
        "        d_optimizer,\n",
        "        device,\n",
        "        **hparams\n",
        "    )\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        evaluate(generator, **hparams)\n",
        "\n",
        "    epoch += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "acwgangp.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f3a57eea4993a76e91c81c0795acbc3ba67bea0bcd05a3c0238f67cd7ad3c22f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('gan': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
